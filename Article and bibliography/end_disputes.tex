\documentclass{article}

% these lines make double-spaced with wide margins for submission purposes
% comment them out to make it look like a more conventionally formatted article
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\AtBeginDocument{\doublespacing} % activates double spacing for the entire document, footnotes included


\usepackage[
backend=bibtex]{biblatex}
\usepackage{graphicx}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{BOONDOX-cal} % a calligraphic font that includes lowercase letters, will be used with mathcal command
\usepackage{babel, blindtext}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amssymb}
\newenvironment{nohyphen}
  {\tolerance=1% Also consider setting \pretolerance
   \emergencystretch=\maxdimen%
   \hyphenpenalty=10000%
   \hbadness=10000}% \begin{nohyphen}
  {\par}% \end{nohyphen}
 
\addbibresource{end_disputes.bib}

\begin{document}

%\title{A Cradle-to-Grave \\ Algorithmic Game Theory \\ Model of the Tort System}
\title{How Much Do \\ Procedural Devices Matter \\ in an Equilibrating Legal System?}
\author{Michael Abramowicz \\ \href{mailto:abramowicz@law.gwu.edu}{abramowicz@law.gwu.edu} \\ George Washington University Law School}

\maketitle

\begin{abstract}
\begin{nohyphen}
[WRITE ABSTRACT]
\end{nohyphen}
\end{abstract}

\section{Introduction}

In a world of costly litigation, how can procedural mechanisms best advance the cause of the substantive law? This question lies at the heart of much of the law-and-economics literature on issues such as fee shifting, damages multipliers, and burdens of persuasion. Answers, however, have proven elusive. Models suggest that a wide range of policy might be optimal in the real world. Rowe (1984) concluded "that no general prediction of the relative overall effects of the American and English rules ... seems possible." Polinsky \& Rubinfeld (1998), meanwhile, showed that changing assumptions about the settlement process could reverse what had been the general result that the English rule better discourages plaintiffs with low probabilities of prevailing from going to trial. With regard to damages multipliers, the canonical theory presented by Polinsky \& Shavell (1998) is that total damages should equal harm divided by the probability of detection. Even assuming the correctness of this model, a wide range of multipliers might be justified depending on the value of this probability. Similarly, Kaplow (2012), studying burdens of proof, points out how adding consideration of an additional policy dimension could reverse the conclusions of prior models. 

Part of the challenge for the theoretical literature is that any mathematical model can incorporate only so many features of the litigation process before the analysis becomes intractable. And thus even the sign of predicted effects may change depending on which features are included. Worse, even the same model may produce different recommendations, depending on the value of a particular parameter. And models designed to address one procedural choice, such as burdens of proof, may not be well suited to addressing others. One reaction may be a flight from theory. Natural experiments are few and far between, however, and experimental evidence leaves questions about external validity. Thus, we are left with theoretical considerations, which can produce little confidence that we have arrived at the optimal rules for our litigation system. It should not be surprising that these foundational procedural design decisions vary across countries (the American vs. the British rules are so named for a reason) and legal contexts (with antitrust being exceptional in imposing fixed treble damages and with heightened burdens of proof applying in many contexts).

The prospect that any paper with any methodology will get us to the correct answer thus seems small. But we may be able to make some progress by using new tools, particularly taking advantage of the increasing power of computation. This paper seeks to use algorithmic game theory to develop a single theoretical model that can be applied to questions of fee shifting, damages multipliers, and burdens of proof. The expectation is not that we will produce definitive answers about optimal design. But by varying procedural rules and other assumptions with an approach that allows more knobs and variations than most models, perhaps we might at least be able to develop a sense of the answer to the following important meta-question: How much does the choice of procedural mechanism really matter? 

Answering this question, however, requires more than a model of the litigation process itself, even with a better characterization of that process than before. To address the question of overall welfare, we cannot look at litigation outcome variables--such as settlement rates or accuracy--in isolation. Rather, we must assess the ramifications of changes in the litigation system for primary behavior. As Shavell (1997) recognized, litigation is rife with externalities. These include the legal costs that litigants impose on one another, but perhaps as importantly, the mere expectation of litigation may affect others through deterrence (and perhaps overdeterrence). There can thus be too much litigation or too little, but procedural mechanisms can affect the calibration of such incentives. To fully tally the consequence of different choices of procedural mechanisms, we must examine not only the effects of such mechanisms on any given suit, but also on the legal system as a whole. Even if we cannot be sure of the precise consequences of procedural choices for litigation costs, we may be able to gain appreciate of the extent to which the system can equilibrate. That is, to what extent might increases in the cost of trying any particular case be made up by a reduction in the number of cases overall, either because fewer disputes arise (perhaps because of less injury) or because more cases settle?

Given the challenges of mathematical modeling, the theoretical literature has for the most part avoided the challenge of simultaneously modeling both the generation of disputes and the litigation process that resolves them. Models of the tort process may take the litigation system as a given, for example by assuming a fixed cost of litigation cost without fully assessing the dynamics of trial. Shavell (1980)'s canonical comparison of strict liability versus negligence assumes the absence of litigation costs, and even many more modern models, such as Baumann and Rasch (2024)'s model of product liability, adopt a similar assumption. Meanwhile, models of the litigation process itself, such as models of fee shifting, may begin from the assumption that a dispute has occurred, thus ignoring the possibility that a different litigation system might have avoided an accident or other source of controversy. Argenton and Wang (2023) is just one of many recent examples that simply assume the existence of a dispute. 

Some modelers have commented on the design of the litigation process using models in which the generation of disputes is endogenous, but the models of the litigation process must necessarily make great simplifications about the process of adjudication itself. Png (1987)'s model is one of the first in which injurers vary in the cost of care and choose care endogenously, and the entire game is simplified into a extensive form game tree with only 15 nodes. His model demonstrates that the litigation process that the litigation process shapes incentives for care. Polinsky and Rubinfeld (1988) show that optimal liability may require an increase or decrease in damages to balance the goals of optimizing care and minimizing litigation expenditures, but they too assume no judicial error. Spier (1994) provides a sophisticated model of settlement bargaining and explores trade-offs with respect to whether damages awards should be finely tuned to the level of harm, but she too assumes no errors in measuring liability. Meanwhile, Polinsky and Shavell (2014) allow for litigants to face fixed and variable costs of litigation depending on the level of damages, but courts again adjudicate without error.

Yet the possibility of judicial error may be critical to assessing the efficiency of procedural mechanisms. If, for example, treble damages are assessed sometimes against a not truly liable party, that might be problematic even if the treble damages help mitigate the danger of under-deterrence. One scholar has furnished a model with endogenous disputes and imperfect adjudication, Keith Hylton. Over three papers, Hylton developed what he called a "cradle to grave" model of litigation. In his models, potential injurers must decide how much to take care, which determines how many accidents occur, and which in turn result in lawsuits in which there might or might not be fee shifting. In Hylton (1990), Hylton (1993) and Hylton (2002), the potential tortfeasor draws a random cost of care and then compares it to the benefit in expected liability savings from compliance, taking into account the risk of type-1 and type-2 errors. The first article does not explicitly model settlement, while the second assumes that cases settle whenever there is a zone of agreement (that is, the plaintiff's minimum acceptable settlement is not greater than the defendant's maximum offer). The third article features a Bayesian settlement model in which plaintiffs play mixed strategies in determining whether to accept defendants' offers.  

To accomplish the remarkable feat of finding equilibria across both care and litigation decisions, Hylton necessarily must make some sacrifices in the realism of the model of litigation. While these models admit of judicial error, the risk of error is no greater when the level of care is close to the legal standard than when it is far from it. In addition, the strategic interactions between plaintiffs and defendants are stylized in order to yield tractable equilibria: bargaining is reduced to simple settlement zones in the second paper, and the informational structure is entirely one sided in the third of the trilogy, leaving aside the complexity of two-sided asymmetric information. Though defendants in reality may have more knowledge of their own take care decisions, that advantage is mitigated by discovery. Thus, parties are likely both informed about the probability of liability to some imperfect degree. 

Recent literature has made progress in modeling two-sided asymmetric information. Earlier models, such as Bebchuk (1984) and Daughety and Reinganum (1994), allowed for two-sided asymmetric information by granting each party information on different quantities, for example with one party knowing the level of damages and the other party knowing the level of liability. But Friedman and Wittman (2007) and Klerman, Lee and Liu (2018) model the situation in which each party has independent private information about the same issue, such as the level of damages. Dari-Mattiacci and Saraceno (2020) managed to incorporate an analysis of the effect of fee shifting on such information. Following Friedman and Wittman, Dari-Mattiacci and Saraceno assume that each party receives an independent signal of the level of damages and that the total damages is equal to the sum of the signals.

As Abramowicz (2025a) pointed out, however, tractability required a number of critical assumptions, such as relatively low litigation costs, that every potential lawsuit is always contested, and that a linkage exists between the degree of information asymmetry and the true merits of the case. Rather than complicate an already intricate mathematical model, Abramowicz switched to using an algorithmic game theory algorithm to study similar models of asymmetric information. The linear programming algorithm, developed by von Stengel, van den Elzen, and Talman (2002), identifies exact perfect Bayesian Nash equilibria in extensive form game trees. The article applied this algorithm to extensive form games of over 16,000 nodes, allowing incorporation and variation of a number of game features that could not easily be jointly modeled mathematically. These features included uncertainty about liability rather than damages, risk aversion, and options not to sue or defend, both at the outset of litigation and after the failure of negotiation.

The results strongly suggest that generalizations based on simpler models may not survive more robust specification. For example, while Dari-Mattiacci and Saraceno found that the English (loser pays) rule would be relatively advantageous in a jurisdiction with relatively low litigation costs and the American rule would be advantageous in a jurisdiction with relatively high litigation costs. None of the major computational specifications supported both of these results. Of course, computational results will not necessarily be robust either. Abramowicz (2025b) modifies the earlier model, featuring game trees of over 45,000 nodes that enable correlated instead of independent signals. That is, each party receives a noisy estimate of the true value of the litigation. In this setting, fee shifting can have complicated strategic effects. On one hand, it may lead parties with weak cases to give up or settle on unfavorable terms. On the other, especially when costs are relatively high, it may encourage a party to bluff in the hope that the other party will quit first. 

These conclusions have their own limitations. A significant one is that both of these computational analysis feature disputes that are exogenously generated, with a $\frac{1}{2}$ chance of a case being one in which the defendant is truly liable and an equal chance of being one in which the defendant is not truly liable. Truly liable cases will tend to have stronger evidence for the plaintiff than not truly liable cases, though the distribution of litigation strength given true liability is also set based on an arbitrary parameter. In essence, in these models, as in many litigation models, cases in effect fall from the sky. This leaves unresolved questions of whether the conclusions would be different if there were a different distribution of truly liable vs. not truly liable cases. More critically, it elides the interaction effects between the litigation process and the generation of disputes. 

This article applies algorithmic game theory, albeit with a different algorithm that makes it feasible to have still larger game trees of [FILL IN]. The greater size of these game trees makes it feasible to integrate potential tortfeasors' decisions about whether to take care, while still maintaining the richness of the bargaining framework of the earlier papers. It thus continues Hylton's project of modeling litigation cradle to grave, while allowing for two-sided asymmetric information. Each party's signals span multiple levels of litigation quality, and settlements can occur at each of multiple levels. Instead of one party being limited to accepting or rejecting the other party's settlement offer, the parties follow the Chaterjee and Samuelson (1983) bargaining, in which each party submits an offer and cases settle at the midpoint if the defendant's offer exceeds the plaintiff's. Although the algorithm uses floating point numbers and finds approximate equilibria, unlike the exact algorithm operating on rational numbers of the earlier paper, these equilibria are measurably quite close to perfect Bayesian Nash equilibria. 

This article's analysis is not limited to fee shifting. It also considers two other procedural variations: damages multiples and alterations in the liability threshold. Some simulations intersect multiple such variations, to enable consideration, for example, a regime in which it is difficult to establish liability but liability once established is heavy. With each simulation, it is possible to observe the sum of precaution, injury, and litigation costs, and differences across simulations can thus be at least tentatively attributed to differences in parameters and, in particular, differences in legal regimes. Though it is difficult to encapsulate all of the article's findings in a single conclusion, a central point emerges: When lawsuits are generated endogenously based on the potential defendant's level of care, the adjustments in that level to the legal environment will generally prevent extreme variation in total costs. If liability levels are high, for example, precaution will be relatively high, but injury and litigation will be relatively low. That does not mean that the procedural mechanisms are entirely irrelevant, and certainly at extremes of the cost continuum (very low or very high litigation costs), some clear conclusions emerge. But the effects of even aggressive procedural mechanisms such as damages multiples are much more muted than one might think. 

[SUMMARY OF CONCLUSIONS]

\section{An Extensive Form Endogenous Litigation Game}

The approach that would be most consistent with Hylton's and indeed the broader literature on the economics of accidents would be to allow the defendant to choose a level of care, aware of the implications of that level of care for the probability that an accident occurs. Though perhaps plausible in some cases, this approach would have a serious drawback: The defendant would necessarily know how much care was exerted and therefore the quality of the lawsuit. The model would thus become a one-sided asymmetric information model. Yet in reality, both plaintiffs and defendants will often be uncertain about the outcome of litigation. Moreover, after initial accumulation and sharing of information, whether through formal discovery or otherwise, it is not obvious that the defendant's knowledge in every case will necessarily be better than the plaintiff's. Such an asymmetry might manifest in many cases, but it would be preferable if that possibility could be explored as one setting of the model. A neutral default setting would be one in which each side has equal insight into litigation quality. 

A modeling approach addressing this concern emerges from the recognition that in many real settings, both parties can observe what level of precaution the injurer actually took (for example, whether a machine guard was installed or which safety protocol was followed), and may even have strong information about the cost of such precautions. Meanwhile, the parties also may know what precautions the injurer forewent and how much such additional precaution might have cost. Nonetheless, there might still be uncertainty concerning how \emph{effective} the marginal precaution not taken would have been at reducing risk and whether such a risk reduction would have been cost-justified. Effectiveness depends on technological fit, local conditions, and other hidden factors that are not fully verifiable or knowable ex ante or perhaps even after an accident occurs. Such questions can be particularly challenging because they are counter-factual. Disputes in tort cases will thus often concern whether the defendant should have taken a more cautious path than the defendant actually took. To be sure, there may sometimes be debates as well as to what the defendant actually did and as to what a hypothetical precaution would have cost, but even with computation, analytic tractability makes desirable focus on a single source of uncertainty. For the purpose of the model in this article, the fount of uncertainty will thus concern the level of \emph{precaution power}, that is the extent to which expenditures on precaution would have reduced the probability of an accident. Each party knows the \emph{precaution level} but will receive only a signal of precaution power. 

This section thus presents a single extensive-form model in which precaution and litigation are determined jointly in equilibrium under a negligence rule with imperfect adjudication and two-sided private information. Chance determines an underlying state that governs how effective precaution is at reducing accident risk. The defendant chooses a discrete precaution level before any accident occurs. The precaution level and chance then jointly determine whether the defendant causes an accident. If the defendant does not cause an accident, there is nonetheless some chance, unrelated to the level of precaution, that an accident occurs and is wrongly attributed to the defendant. 

Assuming an accident occurs, the plaintiff decides whether to file suit, the defendant decides whether to answer or default, the parties engage in a one-shot simultaneous-offers bargaining stage (with acceptance if the defendant’s offer weakly exceeds the plaintiff’s demand). If there is no settlement the case proceeds to trial unless one party decides to quit upon settlement failure. At trial, a court renders a binary liability verdict based on the liability threshold and on its own noisy signal of precaution power, again assuming knowledge of the precaution level. Payoffs incorporate damages (with an optional multiplier), litigation costs, and fee rules. Social welfare accounts for precaution costs, defendant-caused accident losses, and litigation costs. 

\subsection{Players, timeline, and information}
\emph{Players and roles.} An extensive-form game tree can fully capture the formal game summarized above. The game features two strategic players and Chance. The \emph{defendant} (potential injurer) chooses whether to engage in the underlying activity, and, if so, a discrete precaution level. (The choice whether to engage in the activity and thus receive the fruits of that activity has little role in the analysis in this paper, but is included both for analytic completeness and as a source for analysis in future work.) The \emph{plaintiff} (victim) decides whether to file, whether to quit before trial if settlement fails, and which demand to submit in simultaneous offers. The defendant also decides whether to answer, whether to quit before trial if settlement fails, and what demand to submit. The \emph{court} is modeled as a chance node that observes a noisy liability signal at trial and returns a binary liability verdict.

In the baseline calibration used for analysis, the number of hidden precaution-power states is $n_H=8$, the number of discrete precaution levels is $n_K=8$, and each party’s liability signal has $n_{S_P}=n_{S_D}=8$ levels. For purposes of illustration, however, we set $n_H = n_K = S_P = S_D = 2$ (for the hidden state, precaution levels, and the plaintiff/defendant signals), corresponding to a miniature version of the game, solely to make the figures readable. Figure \ref{fig:smalltree} provides a zoomed-out 

 \begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth,height=0.3\textheight]{../Figures/smalltree.pdf}
  \caption{Zoomed out version of the miniaturized version of the game tree.}
  \label{fig:smalltree.pdf}
\end{figure}

\emph{Timeline.} The game proceeds in three stages that correspond to the diagram panels. For each stage, we first present the technical structure of the game, and then discuss how the corresponding figure illustrates that structure. Note that the actual game tree used to compute equilibria is \emph{simplified}, in that the initial plaintiff and defendant signals are not explicitly drawn as chance nodes. Instead, their distributions are reconstructed using Bayesian updating, as explained in the Appendix. The conceptual trees shown here, however, depict the signals explicitly in order to make the strategic structure of the model transparent.

\begin{enumerate}
  \item \textbf{Stage I: Information, activity, and precaution}

Nature draws a hidden precaution--power state $\theta \in \Theta = \{1,\dots,n_H\}$ uniformly at random. Conditional on $\theta$, the defendant privately observes a liability signal $s_D \in \mathcal{S}_D = \{1,\dots,n_{S_D}\}$ and the plaintiff privately observes a liability signal $s_P \in \mathcal{S}_P = \{1,\dots,n_{S_P}\}$. The defendant then decides whether to engage in the activity, which yields a baseline benefit of $1.0 \times 10^{-3}$ if undertaken, and, if the defendant engages, chooses a precaution level $k \in K = \{0,\dots,n_K-1\}$. Note that the lowest level here corresponds to no precaution undertaken at all.

\paragraph{Accident arrival.}
Let the hidden \emph{precaution–power} state be $\theta\in\{1,\dots,n_H\}$ and the chosen precaution level be $k\in\{0,\dots,K\}$.  We index these on $[0,1]$ via
\[
\varphi(\theta) \;=\; \frac{\theta}{\,n_H+1\,}, 
\qquad
\tau(k) \;=\; \frac{k}{\,K\,}.
\]
The probability that the defendant \emph{causes} an accident depends jointly on the hidden precaution–power $\varphi$ and the precaution level $\tau$.  At $\tau=0$ (no precaution), the probability is $p_{\max}$.  At $\tau=1$ (maximum precaution), the probability approaches a floor that itself depends on $\varphi$, interpolating between $p_{\min}^{\varphi=0}$ when precaution power is weakest and $p_{\min}^{\varphi=1}$ when precaution power is strongest:
\begin{equation}
p_{\mathrm{caused}}(\theta,k)
\;=\;
p_{\min}\!\bigl(\varphi(\theta)\bigr)
\;+\;
\bigl(p_{\max}-p_{\min}\!\bigl(\varphi(\theta)\bigr)\bigr)\,
\bigl(1-\tau(k)\bigr)^{\,\alpha\!\bigl(\varphi(\theta)\bigr)}.
\label{eq:pcaused}
\end{equation}
with linear schedules
\[
p_{\min}(\varphi) \;=\; p_{\min}^{\varphi=0} + \bigl(p_{\min}^{\varphi=1}-p_{\min}^{\varphi=0}\bigr)\varphi,
\qquad
\alpha(\varphi) \;=\; \alpha^{\varphi=0} + \bigl(\alpha^{\varphi=1}-\alpha^{\varphi=0}\bigr)\varphi.
\]

The curvature parameter $\alpha(\varphi)$ plays a crucial role in shaping how the probability of an accident falls as precaution increases. A constant value of $\alpha$ would imply that the “trajectory” of risk reduction is the same regardless of the underlying precaution–power: hidden states would differ only in the ultimate floor $p_{\min}(\varphi)$ that precaution can reach. While this would capture differences in endpoints, it would not capture differences in the path by which those endpoints are approached. Allowing $\alpha$ to vary with $\varphi$ makes it possible for precaution power to affect not only the minimum accident probability but also the pace at which accident risk declines along the way. When $\varphi$ is low, precaution is intrinsically weak, and $\alpha(\varphi)$ is relatively large, so that initial increments of precaution produce noticeable risk reduction but quickly run into diminishing returns. When $\varphi$ is high, precaution is intrinsically strong, and $\alpha(\varphi)$ is smaller, so that precaution remains effective throughout the full range of $\tau$. This difference means that in weak-power environments defendants face a world where “most of the good is done early,” while in strong-power environments additional care continues to yield substantial benefits. In short, varying $\alpha(\varphi)$ allows the model to distinguish between technologies of care that lose effectiveness quickly and those for which precaution remains potent across successive increments, a distinction that would be invisible if $\alpha$ were held constant.



The total probability that an accident is \emph{observed and attributed to the defendant} adds wrongful attributions with probability $\pi_{\mathrm{wrong}}$, conditional on no caused accident:
\begin{equation}
\Pr(A=1\mid \theta,k)
\;=\;
p_{\mathrm{caused}}(\theta,k)
\;+\;
\bigl(1-p_{\mathrm{caused}}(\theta,k)\bigr)\,\pi_{\mathrm{wrong}}.
\label{eq:accident-total}
\end{equation}

\paragraph{Default calibration.}
Unless otherwise stated, simulations use
\[
p_{\max}=10^{-4},\qquad
p_{\min}^{\varphi=0}=8\times 10^{-5},\qquad
p_{\min}^{\varphi=1}=2\times 10^{-5},
\]
\[
\alpha^{\varphi=0}=2,\qquad
\alpha^{\varphi=1}=1.5,\qquad
\pi_{\mathrm{wrong}}=10^{-5}.
\]



If $A=1$, the case proceeds to Stage II.

Figure \ref{fig:smalltree_beginning.pdf} provides the first stage in the miniature version of the game. The diagram shows the split of hidden states at the top, the branching for defendant and plaintiff signals just below, the defendant’s decision to engage in the activity and select a precaution level, and the accident node at the bottom. The printed probabilities on the accident branches are consistent with increased precaution reducing risk: approximately $1.10 \times 10^{-4}$ at the lower level of precaution versus $8.12 \times 10^{-5}$ at the higher level. (The formulas used to devise these probabilities are discussed below.) These small values are consistent with an environment in which accidents are highly unlikely to occur but quite costly relative to precaution cost in the event that they do occur. An advantage of the model is that it easily accommodates this common feature of tort precaution, instead of requiring a relatively high probability of an accident, as some Monte Carlo computational models would. (Informal experimentation suggests that the results in the paper are generally qualitatively similar if accident is made much more common and precaution cost, correspondingly higher.)

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_beginning.pdf}
    \caption{Stage I: hidden state, private signals, activity/precaution choice, and accident realization (illustrative tree with two levels for readability).}
    \label{fig:smalltree_beginning.pdf}
  \end{figure}


  \item \textbf{Stage II: Filing and case entry}

If $A=1$, a wrongful--attribution flag $W \in \{0,1\}$ is drawn with probability $\pi_{\text{wrong}}$. In that event, the observed accident is not in fact caused by the defendant but is nonetheless causally attributed to him. We assume that such false--positive attributions occur far less frequently than genuine accidents, but their presence is essential: the rare event of wrongful attribution provides a channel through which we can analyze the welfare implications of error and the efficiency of procedural mechanisms. Later in the article, we explore how this source of noise interacts with litigation decisions and modifies the effects of policy interventions. 

If an accident occurs, the plaintiff decides whether to file suit after observing her private signal. The defendant then decides whether to answer (contest) or to default. A default ends the case immediately with a damages transfer per the liability rule; answering moves the case into bargaining.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_mid.pdf}
    \caption{Stage II: filing, answer/default, and entry into bargaining (illustrative tree with two levels for readability).}
    \label{fig:smalltree_mid.pdf}
  \end{figure}

  \item \textbf{Stage III: Bargaining, quit options, and trial}

  The parties submit one round of simultaneous offers: the plaintiff demands $o_P$ and the defendant offers $o_D$. If $o_D \ge o_P$, settlement occurs at the midpoint; otherwise there is impasse. If there is impasse, the plaintiff may quit; if she proceeds, the defendant may quit before trial. If both proceed, the court observes its own noisy liability signal $s_C \in \mathcal{S}_C = \{1,\dots,n_{S_C}\}$ and returns a binary verdict $V \in \{0,1\}$. A liable verdict transfers damages (possibly multiplied) and assigns fee liability according to the rule; all stage costs are also subtracted from payoffs.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_end.pdf}
    \caption{Stage III: simultaneous offers, quit options, and binary court verdict (illustrative tree with two levels for readability).}
    \label{fig:smalltree_end.pdf}
  \end{figure}
\end{enumerate}

\emph{Information sets.} The plaintiff’s and defendant’s liability signals are private; each party knows the model primitives and distributions but not the other’s realized signal or the hidden state. Actions in the litigation block are observed as they occur (filing, answering, offers, and quits). The court’s internal signal is not observed by the parties; they observe only the binary verdict. Each party has perfect recall, meaning that its own decisions and the signals available to it remain part of its information set throughout the game. 


\printbibliography
\end{document}
