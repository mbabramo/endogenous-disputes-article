\documentclass{article}

% these lines make double-spaced with wide margins for submission purposes
% comment them out to make it look like a more conventionally formatted article
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\AtBeginDocument{\doublespacing} % activates double spacing for the entire document, footnotes included


\usepackage[
backend=bibtex]{biblatex}
\usepackage{graphicx}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{BOONDOX-cal} % a calligraphic font that includes lowercase letters, will be used with mathcal command
\usepackage{babel, blindtext}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amssymb}
\newenvironment{nohyphen}
  {\tolerance=1% Also consider setting \pretolerance
   \emergencystretch=\maxdimen%
   \hyphenpenalty=10000%
   \hbadness=10000}% \begin{nohyphen}
  {\par}% \end{nohyphen}
 
\addbibresource{end_disputes.bib}

\begin{document}

%\title{A Cradle-to-Grave \\ Algorithmic Game Theory \\ Model of the Tort System}
\title{How Much Do \\ Procedural Devices Matter \\ in an Equilibrating Legal System?}
\author{Michael Abramowicz \\ \href{mailto:abramowicz@law.gwu.edu}{abramowicz@law.gwu.edu} \\ George Washington University Law School}

\maketitle

\begin{abstract}
\begin{nohyphen}
[WRITE ABSTRACT]
\end{nohyphen}
\end{abstract}

\section{Introduction}

In a world of costly litigation, how can procedural mechanisms best advance the cause of the substantive law? This question lies at the heart of much of the law-and-economics literature on issues such as fee shifting, damages multipliers, and burdens of persuasion. Answers, however, have proven elusive. Models suggest that a wide range of policy might be optimal in the real world. Rowe (1984) concluded "that no general prediction of the relative overall effects of the American and English rules ... seems possible." Polinsky \& Rubinfeld (1998), meanwhile, showed that changing assumptions about the settlement process could reverse what had been the general result that the English rule better discourages plaintiffs with low probabilities of prevailing from going to trial. With regard to damages multipliers, the canonical theory presented by Polinsky \& Shavell (1998) is that total damages should equal harm divided by the probability of detection. Yet Craswell  (1999) shows that constant multipliers may be more administrable while still providing optimal deterrence. Similarly, Kaplow (2012), studying burdens of proof, points out how adding consideration of an additional policy dimension could reverse the conclusions of prior models. 

Part of the challenge for the theoretical literature is that any mathematical model can incorporate only so many features of the litigation process before the analysis becomes intractable. And thus even the sign of predicted effects may change depending on which features are included. Worse, even the same model may produce different recommendations, depending on the value of a particular parameter. And models designed to address one procedural choice, such as burdens of proof, may not be well suited to addressing others. An understandable reaction may be a flight from theory. Natural experiments are few and far between, however, and experimental evidence leaves questions about external validity. Thus, we are left with theoretical considerations, which can produce little confidence that we have arrived at the optimal approaches to these most foundational aspects of our litigation system. It should not be surprising that these foundational procedural design decisions vary across countries (the American vs. the British rules are so named for a reason) and legal contexts (with antitrust being exceptional in imposing fixed treble damages and with heightened burdens of proof applying in many contexts).

The prospect that any paper with any methodology will get us to the correct answer thus seems small. But we may be able to make some progress by using new tools, particularly taking advantage of the increasing power of computation. This paper seeks to use algorithmic game theory to develop a single theoretical model that can be applied to questions of fee shifting, damages multipliers, and burdens of proof. The expectation is not that we will produce definitive answers about optimal design. But by varying procedural rules and other assumptions with an approach that allows more knobs and variations than most models, perhaps we might at least be able to develop a sense of the answer to the following important meta-question: How much does the choice of procedural mechanism really matter? 

Answering this question, however, requires more than a model of the litigation process itself, even with a better characterization of that process than before. To address the question of overall welfare, we cannot look at litigation outcome variables--such as settlement rates or accuracy--in isolation. Rather, we must assess the ramifications of changes in the litigation system for primary behavior. As Shavell (1997) recognized, litigation is rife with externalities. These include the legal costs that litigants impose on one another, but perhaps as importantly, the mere expectation of litigation may affect others through deterrence (and perhaps overdeterrence). There can thus be too much litigation or too little, but procedural mechanisms can affect the calibration of such incentives. To fully tally the consequence of different choices of procedural mechanisms, we must examine not only the effects of such mechanisms on any given suit, but also on the legal system as a whole. Even if we cannot be sure of the precise consequences of procedural choices for litigation costs, we may be able to gain appreciation of the extent to which the system can equilibrate. For example, to what extent might increases in the cost of trying any particular case be made up by a reduction in the number of cases overall, either because fewer disputes arise (perhaps because of less injury) or because more cases settle? 

Given the challenges of mathematical modeling, the theoretical literature has for the most part avoided the challenge of simultaneously modeling both the generation of disputes and the litigation process that resolves them. Models of the tort process often take the litigation system as a given, for example by assuming a fixed cost of litigation cost without fully assessing the dynamics of trial. Shavell (1980)'s canonical comparison of strict liability versus negligence assumes the absence of litigation costs, and even many more modern models, such as Baumann and Rasch (2024)'s model of product liability, reasonably adopt a similar assumption. Meanwhile, models of the litigation process itself, such as models of fee shifting, may begin from the assumption that a dispute has occurred, thus ignoring the possibility that a different litigation system might have avoided an accident or other source of controversy. Argenton and Wang (2023) is just one of many recent examples that assume the existence of a dispute because doing so allows undistracted focus on the litigation process.

Some modelers have commented on the design of the litigation process using models in which the generation of disputes is endogenous, but have been forced to accept great simplifications about the process of adjudication itself. Png (1987)'s model is one of the first in which injurers vary in the cost of care and choose care endogenously, and the entire game is simplified into a extensive form game tree with only 15 nodes. His model demonstrates that the litigation process shapes incentives for care but leaves open many interesting questions of institutional design. Polinsky and Rubinfeld (1988) show that optimal liability may require an increase or decrease in damages to balance the goals of optimizing care and minimizing litigation expenditures, but they unrealistically assume no judicial error. Spier (1994) provides a sophisticated model of settlement bargaining and explores trade-offs with respect to whether damages awards should be finely tuned to the level of harm, but she too assumes no errors in measuring liability. Meanwhile, Polinsky and Shavell (2014) allow for litigants to face fixed and variable costs of litigation depending on the level of damages, but courts again adjudicate without error. Yet the possibility of judicial error may be critical to assessing the efficiency of procedural mechanisms. If, for example, treble damages are assessed sometimes against a not truly liable party, that might be problematic even if the treble damages help mitigate the danger of under-deterrence. 

One scholar has furnished a model with endogenous disputes and imperfect adjudication, Keith Hylton. Over three papers, Hylton developed what he called a "cradle to grave" model of litigation. In his models, potential injurers must decide how much to take care, and these decisions determine how many accidents occur, which in turn result in lawsuits in which there might or might not be fee shifting. In Hylton (1990), Hylton (1993) and Hylton (2002), the potential tortfeasor draws a random cost of care and then compares it to the benefit in expected liability savings from compliance, taking into account the risk of type-1 and type-2 errors. The first article does not explicitly model settlement, while the second assumes that cases settle whenever there is a zone of agreement (that is, the plaintiff's minimum acceptable settlement is not greater than the defendant's maximum offer). The third article features a Bayesian settlement model in which plaintiffs play mixed strategies in determining whether to accept defendants' offers.  

To accomplish the remarkable feat of finding equilibria across both care and litigation decisions, Hylton necessarily must make some sacrifices in the realism of the model of litigation. While these models admit of judicial error, the risk of error is no greater when the level of care is close to the legal standard than when it is far from it. In addition, the strategic interactions between plaintiffs and defendants are stylized in order to yield tractable equilibria: bargaining is reduced to simple settlement zones in the second paper, and the informational structure is entirely one sided in the third of the trilogy, thus avoiding the methodological complexity of two-sided asymmetric information. Though defendants in reality may have more knowledge of their own take care decisions, that advantage is mitigated by discovery. Thus, parties are likely both informed about the probability of liability to some imperfect degree.

Recent literature, meanwhile, has made progress in modeling two-sided asymmetric information, though without Hylton's innovation of endogenous disputes. Earlier models, such as Bebchuk (1984) and Daughety and Reinganum (1994), allowed for two-sided asymmetric information by granting each party information on different quantities, for example with one party knowing the level of damages and the other party knowing the level of liability. But Friedman and Wittman (2007) and Klerman, Lee and Liu (2018) model the situation in which each party has independent private information about the same issue, such as the level of damages. Dari-Mattiacci and Saraceno (2020) managed to incorporate an analysis of the effect of fee shifting on such information. Following Friedman and Wittman, Dari-Mattiacci and Saraceno assume that each party receives an independent signal of the level of damages and that the total damages is equal to the sum of the signals.

As Abramowicz (2025a) pointed out, however, tractability required a number of critical assumptions, such as relatively low litigation costs, that every potential lawsuit is always contested, and that a linkage exists between the degree of information asymmetry and the true merits of the case. Rather than complicate an already intricate mathematical model, Abramowicz switched to using a computational game theory algorithm to study similar models of asymmetric information. The linear programming algorithm, developed by von Stengel, van den Elzen, and Talman (2002), identifies exact perfect Bayesian Nash equilibria in extensive form game trees. The article applied this algorithm to extensive form games of over 16,000 nodes, allowing incorporation and variation of a number of game features that could not easily be jointly modeled mathematically. These features included uncertainty about liability rather than damages, risk aversion, and options not to sue or defend, both at the outset of litigation and after the failure of negotiation.

The results strongly suggest that generalizations based on simpler models may not survive more robust specification. For example, while Dari-Mattiacci and Saraceno found that the English (loser pays) rule would be relatively advantageous in a jurisdiction with relatively low litigation costs and the American rule would be advantageous in a jurisdiction with relatively high litigation costs. None of the major computational specifications supported both of these results. Of course, computational results will not necessarily be robust either. Abramowicz (2025b) modifies the earlier model, featuring game trees of over 45,000 nodes that enable correlated instead of independent signals. That is, each party receives a noisy estimate of the true value of the litigation. In this setting, fee shifting can have complicated strategic effects. On one hand, it may lead parties with weak cases to give up or settle on unfavorable terms. On the other, especially when costs are relatively high, it may encourage a party to bluff in the hope that the other party will quit first. 

A significant limitation of these computational analyses is that they feature disputes that are exogenously generated, with a $\frac{1}{2}$ chance of a case being one in which the defendant is truly liable and an equal chance of being one in which the defendant is not truly liable. Truly liable cases are assumed tend to have stronger evidence for the plaintiff than not truly liable cases, though the distribution of litigation strength given true liability is also set based on an arbitrary parameter. In essence, in these models, as in many litigation models, cases in effect fall from the sky. This leaves unresolved questions of whether the conclusions would be different if there were a different distribution of truly liable vs. not truly liable cases. More critically, it elides the interaction effects between the litigation process and the generation of disputes. The computational approach was able to model how fee-shifting affects cost and accuracy in various environments, but no effort was made to combine these considerations, as Hylton did, in an effort to identify global optimality.

This article applies algorithmic game theory, albeit with a different algorithm that makes it feasible to have still larger game trees of [FILL IN]. The greater size of these game trees makes it feasible to integrate potential tortfeasors' decisions about whether to take care, while still maintaining the richness of the bargaining framework of the earlier papers. It thus continues Hylton's project of modeling litigation cradle to grave, while allowing for two-sided asymmetric information. Each party's signals span multiple levels of litigation quality, and settlements can occur at each of multiple levels. Instead of one party being limited to accepting or rejecting the other party's settlement offer, the parties follow the Chaterjee and Samuelson (1983) bargaining protocol, in which each party submits an offer and cases settle at the midpoint if the defendant's offer exceeds the plaintiff's. Although the algorithm uses floating point numbers and finds approximate equilibria, unlike the exact algorithm operating on rational numbers of the earlier computational analyses, these equilibria are measurably quite close to perfect Bayesian Nash equilibria. 

This article's analysis is not limited to fee shifting. Recognizing Craswell (1999)'s point that a variety of different types of procedural mechanisms might help achieve optimality, this article also considers two other procedural variations: damages multiples and alterations in the liability threshold. Some simulations intersect multiple such variations, to enable consideration, for example, a regime in which it is difficult to establish liability but liability once established is heavy. With each simulation, it is possible to observe the sum of precaution, injury, and litigation costs, and differences across simulations can thus be at least tentatively attributed to differences in parameters and, in particular, differences in legal regimes. Though it is difficult to encapsulate all of the article's findings in a single conclusion, a central point emerges: When lawsuits are generated endogenously based on the potential defendant's level of care, the adjustments in that level to the legal environment will generally prevent extreme variation in total costs. If liability levels are high, for example, precaution will be relatively high, but injury and litigation will be relatively low. That does not mean that the procedural mechanisms are entirely irrelevant, and certainly at extremes of the cost continuum (very low or very high litigation costs), some clear conclusions emerge. But the effects of even aggressive procedural mechanisms such as damages multiples are much more muted than one might think. 

[SUMMARY OF CONCLUSIONS]

\section{An Extensive Form Endogenous Litigation Game}

The approach that would be most consistent with Hylton's and indeed the broader literature on the economics of accidents would be to allow the defendant to choose a level of care, aware of the implications of that level of care for the probability that an accident occurs. Though perhaps plausible in some cases, this approach would have a serious drawback: The defendant would necessarily know how much care was exerted and therefore the quality of the lawsuit. The model would thus become a one-sided asymmetric information model. Yet in reality, both plaintiffs and defendants will often be uncertain about the outcome of litigation. Moreover, after initial accumulation and sharing of information, whether through formal discovery or otherwise, it is not obvious that the defendant's knowledge in every case will necessarily be better than the plaintiff's. Such an asymmetry might manifest in many cases, but it would be preferable if that possibility could be explored as one setting of the model. A neutral default setting would be one in which each side has equal insight into litigation quality. 

A modeling approach addressing this concern emerges from the recognition that in many real settings, both parties can observe what level of precaution the injurer actually took (for example, whether a machine guard was installed or which safety protocol was followed), and may even have strong information about the cost of such precautions. Meanwhile, the parties also may know what precautions the injurer forewent and how much such additional precaution might have cost. Nonetheless, there might still be uncertainty concerning how \emph{effective} the marginal precaution not taken would have been at reducing risk and whether such a risk reduction would have been cost-justified. Effectiveness depends on technological fit, local conditions, and other hidden factors that are not fully verifiable or knowable ex ante or perhaps even after an accident occurs. Such questions can be particularly challenging because they are counter-factual. Disputes in tort cases will thus often concern whether the defendant should have taken a more cautious path than the defendant actually took. To be sure, there may sometimes be debates as well as to what the defendant actually did and as to what a hypothetical precaution would have cost, but even with computation, analytic tractability makes desirable focus on a single source of uncertainty. For the purpose of the model in this article, the fount of uncertainty will thus concern the level of \emph{precaution power}, that is the extent to which expenditures on precaution would have reduced the probability of an accident. Each party knows the \emph{precaution level} but will receive only a signal of precaution power. 

This section thus presents a single extensive-form model in which precaution and litigation are determined jointly in equilibrium under a negligence rule with imperfect adjudication and two-sided private information. Chance determines an underlying state that governs how effective precaution is at reducing accident risk. The defendant chooses a discrete precaution level before any accident occurs. The precaution level and chance then jointly determine whether the defendant causes an accident. If the defendant does not cause an accident, there is nonetheless some chance, unrelated to the level of precaution, that an accident occurs and is wrongly attributed to the defendant. 

Assuming an accident occurs, the plaintiff decides whether to file suit, the defendant decides whether to answer or default, the parties engage in a one-shot simultaneous-offers bargaining stage (with acceptance if the defendant’s offer weakly exceeds the plaintiff’s demand). If there is no settlement the case proceeds to trial unless one party decides to quit upon settlement failure. At trial, a court renders a binary liability verdict based on the liability threshold and on its own noisy signal of precaution power, again assuming knowledge of the precaution level. Payoffs incorporate damages (with an optional multiplier), litigation costs, and fee rules. Social welfare accounts for precaution costs, defendant-caused accident losses, and litigation costs. 

In this section, we will introduce the game by zooming into portions of a miniature version of the extension form game tree and then discussing the algorithm used to find perfect Bayesian Nash equilibria in these trees. More detail about the construction of the game trees is available in the appendices. Appendix A elaborates the formulas that are used for critical calculations, such as the probability of an accident and the probability that the court rules for the plaintiff in a case that goes to trial. Appendix B, meanwhile, describes a simplification that makes calculation much more feasible. The simplification is that the node in which the precaution power level is chosen can be eliminated from the game tree, so long as Bayesian probability is applied both to calculations (such as accident and trial probabilities) and to back out signal values after games are complete. This simplification was tested in relatively small trees by comparing its results to the same simulations run without simplification, and they produced identical results. The details underlying this algorithmic shortcut may be of interest primarily to readers interested in implementing similar simulations.

\subsection{Extensive-form game tree}

An extensive-form game tree can fully capture the formal game summarized above for any particular set of parameter values. The game features two strategic players and Chance. The \emph{defendant} (potential injurer) chooses whether to engage in the underlying activity, and, if so, a discrete precaution level. (The choice whether to engage in the activity and thus receive the fruits of that activity has little role in the analysis in this paper, but is included both for analytic completeness and as a source for analysis in future work.) The \emph{plaintiff} (victim) decides whether to file, whether to quit before trial if settlement fails, and which demand to submit in simultaneous offers. The defendant also decides whether to answer, whether to quit before trial if settlement fails, and what demand to submit. The \emph{court} is modeled as a chance node that observes a noisy liability signal at trial and returns a binary liability verdict.

In the baseline calibration used for analysis, the number of hidden precaution-power states is $n_H=8$, the number of discrete precaution levels is $n_K=8$, and each party’s liability signal has $n_{S_P}=n_{S_D}=8$ levels. In addition, the number of possible settlement offers that the plaintiff and defendant, respectively, may make, is defined as $n_{\mathcal{o}_P} = n_{\mathcal{o}_D} = 8$. In the miniaturized version of the game tree explored here, $n_H = n_K = S_P = S_D = n_{\mathcal{o}_P} = n_{\mathcal{o}_D} = 2$ (for the hidden state, precaution levels, and the plaintiff/defendant signals). Otherwise, parameters are set to the baseline values that we use in the simulation with the larger tree. Figure \ref{fig:smalltree.pdf} provides a zoomed-out view of the miniaturized version of the game. This is designed solely to provide context and a sense of the game complexity even in this miniature game. Zooming into particular portions of the game tree will allow for clearer explication of the game.

 \begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth,height=0.3\textheight]{../Figures/smalltree.pdf}
  \caption{Zoomed out version of the miniaturized version of the game tree.}
  \label{fig:smalltree.pdf}
\end{figure}

The game proceeds in three stages that correspond to the diagram panels. For each stage, we first present the technical structure of the game, and then discuss how the corresponding figure illustrates that structure. 

Figure \ref{fig:smalltree_beginning.pdf} provides the first stage in the miniature version of the game. The diagram shows the split of hidden states at the top, the branching for defendant and plaintiff signals just below, the defendant’s decision to engage in the activity and select a precaution level, and the accident node at the bottom. 

The numbers attached to these nodes provide some intuition. In the portion of the tree fully presented in Figure \ref{fig:smalltree_beginning.pdf}, the precaution power is set randomly to a low value (0.25), with the very bottom of the diagram using ellipses to gesture toward the case in which the precaution power is set randomly to a high value (0.75). With the low precaution power, each party is likely to receive a low signal of precaution power rather than a high signal. Indeed, with the default parameter values, there is approximately an 88\% chance of receiving the signal corresponding to the correct precaution power level. With more precaution power levels and signals, of course, the signal often will deviate at least slightly form the precaution power level, but will be highly correlated with it. The chance probabilities are calculated based on the assumption that a draw from a random distribution is added to the true value and thus becomes noise that obfuscates it. The degree of noise determines the quality of the party's information, and here we assume that each party has equally good information about precaution power.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_beginning.pdf}
    \caption{Stage I: hidden state, private signals, activity/precaution choice, and accident realization (illustrative tree with two levels for readability).}
    \label{fig:smalltree_beginning.pdf}
  \end{figure}

The plaintiff’s and defendant’s liability signals are private; each party knows the model primitives and distributions but not the other’s realized signal or the hidden state. Actions in the litigation block are observed as they occur (filing, answering, offers, and quits). A party's information set consists of any signal that the party receives, the party's own decisions earlier in the game, and public decisions of the opponent. The court’s internal signal is not observed by the parties; they observe only the binary verdict. Each party has perfect recall, meaning that its own decisions and the signals available to it remain part of its information set throughout the game. The extensive form game diagrams denote information sets by placing a number next to a letter; for example, "D26" refers to a particular information set faced by the defendant at the time the defendant must determine whether to engage in the activity. The algorithm for finding a Nash equilibrium must assign a single mixed strategy (i.e., probability of choosing each action) for each information set, even though an information set may recur many times in the game tree.

The defendant then must act on the signal that it receives. The first decision for the defendant is whether to engage in the underlying activity. By engaging in the activity, the defendant receives some benefit. This might be seen as the benefit of driving instead of staying home or pursuing a business activity. The value of the benefit parameter is assumed to be $1.0 \times 10^{-3}$ if undertaken. This is a relatively high value relative to some of the other parameters in this simulation, and thus unless otherwise noted, the defendant always chooses to engage in the activity. This approach, however, opens up the possibility of considering not only the possibility that there might be negative consequences from underdeterrence, but also that overdeterrence of activities that have the potential to lead to tort liability could produce costs (or alternatively benefits, if the relevant activities have negative externalities apart from the torts that may be committed). If the defendant decides not to engage in the underlying activity, then the defendant cannot cause injury to the plaintiff or be thought to have been responsible for any injury to the plaintiff, and so the game ends. The modeling cost of including this branch in the model is very low because it does not exponentially increase the size of the tree.

After deciding to engage in the activity, the defendant must choose a level of precaution. The lowest level of precaution is always zero, so given the assumption in this miniature model of only two levels of precaution, in this example the choice is the binary one whether to take a precaution or not, though in the expanded tree, the choice can span multiple layers of precaution. The incentive for greater precaution is a reduced likelihood of an accident and thus a stronger position in any hypothetical litigation. The printed probabilities on the accident branches are consistent with increased precaution reducing risk: approximately $1.10 \times 10^{-4}$ at the lower level of precaution is a higher risk than the $8.12 \times 10^{-5}$ at the higher level of precaution. These numbers are calculated through the formulas discussed in detail in the appendices.

These probability values are intentionally quite small. The small values are consistent with an environment in which accidents are highly unlikely to occur but quite costly relative to precaution cost in the event that they do occur. For example, someone driving at a high rate of speed still will generally have only a low probability of engaging in an automobile accident. Likewise, even when a dock owner improperly secures a barge, most of the time it won't drift away from the pier. An advantage of the computational game theory algorithm discussed here is that it easily accommodates this common feature of tort precaution, simply calculating the relevant probability values during its walks through the tree. By contrast, some Monte Carlo computational models might need a relatively high accident rate so that they can generate enough cases in which accidents occur to create a meaningful quantity of data. Informal experimentation, however, suggests that the results in the paper are generally qualitatively similar if accident is made much more common and precaution cost, correspondingly higher.

One detail that the formal extensive form game tree obscures is that the model allows not only for the possibility that the defendant causes an injury to the plaintiff, but also that the defendant is wrongfully concluded to have caused the plaintiff's injury. The probability of a wrongful attribution of liability (conditional on the defendant engaging in the activity but not actually causing injury to the plaintiff) is set in the baseline at $1.0 \times 10^{-5}$. This value is set so that for the values of the parameters that we choose, such wrongful attribution remains less likely than proper attribution of liability. The rare event of wrongful attribution provides a channel through which we can analyze the welfare implications of error and the efficiency of procedural mechanisms. 

The accident probabilities listed reflect the sum of the probability that the defendant causes injury to the plaintiff and that the defendant is wrongfully believed to have caused such injury. This nuance is omitted from the game tree because it has no effect whatsoever on game play. Though a more sophisticated model might explicitly model causation, that is not modeled here. Whatever the route to an injury relevant to the model, the legal attribution of causation to the defendant is assumed. The trial itself concerns only whether the defendant exercised standard care, not the issue of causation. Thus, after applying the proper formulas to identify the total accident probability, we can ignore the causation issue in finding perfect Bayesian Nash equilibria. Then, in the final accounting, we can break down the proportion of cases in which causal attribution is wrongful if desired. Note that the model does not reflect that the plaintiff may be injured by someone other than the defendant, because that has no bearing on the defendant's liability or on game play.

If an accident occurs, the plaintiff decides whether to file suit after observing the plaintiff's private signal. If the plaintiff does so, the defendant then decides whether to answer (contest) or to default. A default ends the case immediately with a damages transfer per the liability rule; answering moves the case into bargaining.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_mid.pdf}
    \caption{Stage II: filing, answer/default, and entry into bargaining (illustrative tree with two levels for readability).}
    \label{fig:smalltree_mid.pdf}
  \end{figure}

After the plaintiff files and the defendant answers, we insert—before any settlement proposals—the parties’ contingent exit choices: the plaintiff may elect to abandon if bargaining later fails, and the defendant may elect to default if bargaining later fails. This placement is deliberate. Modeling these “quit if no settlement” decisions \emph{after} every possible offer profile would require intersecting abandon/default with the settlement subgame, exponentially multiplying information sets without changing what the parties can do or the distribution of outcomes. By recording the quit choices immediately after the file/answer node (and keeping them unobserved until they matter), we preserve the same strategic possibilities while dramatically simplifying the tree shown in Figure \ref{fig:smalltree_mid.pdf}.

Bargaining then proceeds exactly as in our earlier models. The plaintiff states a minimum monetary demand (“P Offer”) and the defendant states the most it is willing to pay (“D Offer”). Although the diagram prints P Offer before D Offer, this ordering is irrelevant. Because the defendant does not receive information about the plaintiff offer before announcing its own amount, the decisions are effectively simultaneous. If the offers meet or cross (the defendant's offer is at least as great as the plaintiff's), the case settles at the midpoint of the two numbers and litigation ends. The defendant pays to the plaintiff the amount of the settlement. In addition, each party pays a cost for filing or answering, as well as a cost of bargaining, but then saves the cost of trial. In the baseline condition, $c_{file} = c_{answer} = c_{bargain} = c_{trial} = 0.10$.

If the offers do not meet, we implement the contingent choices recorded earlier: if the plaintiff chose to abandon, the case terminates without judgment; if the defendant chose to default, judgment is entered against the defendant under the operative liability/fee rule; if both parties would quit, Chance determines which party quits first, thus saving the other the trouble. This is illustrated in the 

If neither party precommitted to quit, the case proceeds to adjudication. At trial the court observes an imperfect signal of case quality and returns a binary liability verdict; damages and any fee shifting are applied, and remaining stage costs are assessed. Figure \ref{fig:smalltree_end.pdf} depicts this end phase; we keep notation light here to emphasize the structure of the tree.
.



  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_end.pdf}
    \caption{Stage III: simultaneous offers, quit options, and binary court verdict (illustrative tree with two levels for readability).}
    \label{fig:smalltree_end.pdf}
  \end{figure}

\section*{Appendix A: Formal Accident-Probability Surface}

This appendix collects the mathematical details underlying the accident-probability function used in the model. The main text emphasizes intuition and strategic structure, while here we provide the explicit functional forms and parameterizations. Readers interested in the technical basis for the accident arrival process, including the dependence on the hidden precaution–power state and the chosen precaution level, will find the complete derivations and calibrations below.


\begin{enumerate}
  \item \textbf{Stage I: Information, activity, and precaution}

Nature draws a hidden precaution--power state $\theta \in \Theta = \{1,\dots,n_H\}$ uniformly at random. Conditional on $\theta$, the defendant privately observes a liability signal $s_D \in \mathcal{S}_D = \{1,\dots,n_{S_D}\}$ and the plaintiff privately observes a liability signal $s_P \in \mathcal{S}_P = \{1,\dots,n_{S_P}\}$. The defendant then decides whether to engage in the activity, which yields a baseline benefit of $1.0 \times 10^{-3}$ if undertaken, and, if the defendant engages, chooses a precaution level $k \in K = \{0,\dots,n_K-1\}$. Note that the lowest level here corresponds to no precaution undertaken at all.

\paragraph{Accident arrival.}
Let the hidden \emph{precaution–power} state be $\theta\in\{1,\dots,n_H\}$ and the chosen precaution level be $k\in\{0,\dots,K\}$.  We index these on $[0,1]$ via
\[
\varphi(\theta) \;=\; \frac{\theta}{\,n_H+1\,}, 
\qquad
\tau(k) \;=\; \frac{k}{\,K\,}.
\]
The probability that the defendant \emph{causes} an accident depends jointly on the hidden precaution–power $\varphi$ and the precaution level $\tau$.  At $\tau=0$ (no precaution), the probability is $p_{\max}$.  At $\tau=1$ (maximum precaution), the probability approaches a floor that itself depends on $\varphi$, interpolating between $p_{\min}^{\varphi=0}$ when precaution power is weakest and $p_{\min}^{\varphi=1}$ when precaution power is strongest:
\begin{equation}
p_{\mathrm{caused}}(\theta,k)
\;=\;
p_{\min}\!\bigl(\varphi(\theta)\bigr)
\;+\;
\bigl(p_{\max}-p_{\min}\!\bigl(\varphi(\theta)\bigr)\bigr)\,
\bigl(1-\tau(k)\bigr)^{\,\alpha\!\bigl(\varphi(\theta)\bigr)}.
\label{eq:pcaused}
\end{equation}
with linear schedules
\[
p_{\min}(\varphi) \;=\; p_{\min}^{\varphi=0} + \bigl(p_{\min}^{\varphi=1}-p_{\min}^{\varphi=0}\bigr)\varphi,
\qquad
\alpha(\varphi) \;=\; \alpha^{\varphi=0} + \bigl(\alpha^{\varphi=1}-\alpha^{\varphi=0}\bigr)\varphi.
\]

The curvature parameter $\alpha(\varphi)$ plays a crucial role in shaping how the probability of an accident falls as precaution increases. A constant value of $\alpha$ would imply that the “trajectory” of risk reduction is the same regardless of the underlying precaution–power: hidden states would differ only in the ultimate floor $p_{\min}(\varphi)$ that precaution can reach. While this would capture differences in endpoints, it would not capture differences in the path by which those endpoints are approached. Allowing $\alpha$ to vary with $\varphi$ makes it possible for precaution power to affect not only the minimum accident probability but also the pace at which accident risk declines along the way. When $\varphi$ is low, precaution is intrinsically weak, and $\alpha(\varphi)$ is relatively large, so that initial increments of precaution produce noticeable risk reduction but quickly run into diminishing returns. When $\varphi$ is high, precaution is intrinsically strong, and $\alpha(\varphi)$ is smaller, so that precaution remains effective throughout the full range of $\tau$. This difference means that in weak-power environments defendants face a world where “most of the good is done early,” while in strong-power environments additional care continues to yield substantial benefits. In short, varying $\alpha(\varphi)$ allows the model to distinguish between technologies of care that lose effectiveness quickly and those for which precaution remains potent across successive increments, a distinction that would be invisible if $\alpha$ were held constant.



The total probability that an accident is \emph{observed and attributed to the defendant} adds wrongful attributions with probability $\pi_{\mathrm{wrong}}$, conditional on no caused accident:
\begin{equation}
\Pr(A=1\mid \theta,k)
\;=\;
p_{\mathrm{caused}}(\theta,k)
\;+\;
\bigl(1-p_{\mathrm{caused}}(\theta,k)\bigr)\,\pi_{\mathrm{wrong}}.
\label{eq:accident-total}
\end{equation}

\paragraph{Default calibration.}
Unless otherwise stated, simulations use
\[
p_{\max}=10^{-4},\qquad
p_{\min}^{\varphi=0}=8\times 10^{-5},\qquad
p_{\min}^{\varphi=1}=2\times 10^{-5},
\]
\[
\alpha^{\varphi=0}=2,\qquad
\alpha^{\varphi=1}=1.5,\qquad
\pi_{\mathrm{wrong}}=10^{-5}.
\]



If $A=1$, the case proceeds to Stage II.




  \item \textbf{Stage II: Filing and case entry}

  \item \textbf{Stage III: Bargaining, quit options, and trial}

  The parties submit one round of simultaneous offers: the plaintiff demands $o_P$ and the defendant offers $o_D$. If $o_D \ge o_P$, settlement occurs at the midpoint; otherwise there is impasse. If there is impasse, the plaintiff may quit; if she proceeds, the defendant may quit before trial. If both proceed, the court observes its own noisy liability signal $s_C \in \mathcal{S}_C = \{1,\dots,n_{S_C}\}$ and returns a binary verdict $V \in \{0,1\}$. A liable verdict transfers damages (possibly multiplied) and assigns fee liability according to the rule; all stage costs are also subtracted from payoffs.


\end{enumerate}

\printbibliography
\end{document}
