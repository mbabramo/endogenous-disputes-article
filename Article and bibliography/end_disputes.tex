\documentclass{article}

% double-spaced with wide margins for submission purposes
% comment these out to get a more conventional article layout
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\AtBeginDocument{\doublespacing}

% language, encoding, and typography
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{lmodern}
\usepackage{microtype}

% bibliography
\usepackage[backend=bibtex]{biblatex}
\addbibresource{end_disputes.bib}

% quoting and punctuation
\usepackage[autostyle, english=american]{csquotes}
\MakeOuterQuote{"}

% math & algorithms
\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{BOONDOX-cal}
\usepackage{algorithm}
\usepackage{algpseudocode}

% figures, captions, floats, hyperlinks
\usepackage{graphicx}
\usepackage{caption}
\usepackage{placeins}
\usepackage{hyperref}

% drafting aids (optional)
\usepackage{blindtext}

% gentle line-breaking help (keeps hyphenation enabled)
\tolerance=2000
\emergencystretch=2em

% environment: disable hyphenation locally
\newenvironment{nohyphen}
  {\hyphenpenalty=10000 \exhyphenpenalty=10000 \sloppy}
  {\par}

\begin{document}

%\title{A Cradle-to-Grave \\ Algorithmic Game Theory \\ Model of the Tort System}
\title{Evaluating Procedural Devices \\ in an Equilibrating Civil Litigation System}
\author{Michael Abramowicz \\ \href{mailto:abramowicz@law.gwu.edu}{abramowicz@law.gwu.edu} \\ George Washington University Law School}

\maketitle

\begin{abstract}
\begin{nohyphen}
ABSTRACT FORTHCOMING
\end{nohyphen}
\end{abstract}

\section{Introduction}

In a world of costly litigation, how can procedural mechanisms best advance the cause of the substantive law? This question lies at the heart of much of the law-and-economics literature on issues such as fee shifting, damages multipliers, and burdens of persuasion. Answers, however, have proven elusive. Models suggest that a wide range of policy might be optimal in the real world. Rowe (1984) concludes "that no general prediction of the relative overall effects of the American and English rules ... seems possible." Polinsky and Rubinfeld (1998), meanwhile, shows that changing assumptions about the settlement process could reverse what had been the general result that the English rule better discourages plaintiffs with low probabilities of prevailing from going to trial. With regard to damages multipliers, the canonical theory presented by Polinsky and Shavell (1998) is that total damages should equal harm divided by the probability of detection. Yet Craswell  (1999) shows that constant multipliers may be more administrable while still providing optimal deterrence. And studying burdens of proof, Kaplow (2012) points out how adding consideration of an additional policy dimension could reverse the conclusions of prior models. 

Part of the challenge for the theoretical literature is that any mathematical model can incorporate only so many features of the litigation process before the analysis becomes intractable. Even the sign of predicted effects may change depending on which features are included, and even a single model may produce different recommendations, depending on the value of a particular parameter. Models designed to address one procedural choice, such as burdens of proof, may not be well suited to addressing others. The theoretical literature on procedural devices is thus highly fractured. It offers nuanced insights into how particular assumptions may affect the case for different interventions into the civil litigation process, but researchers have not converted on generally agreed upon conclusions about optimal system design. And such convergence seems impossible unless any given theoretical excursion can improve the realism of modeling of settlement bargaining, consider multiple procedural devices in tandem, and more explicitly consider the implications of trade-offs for social welfare.

An understandable reaction may be a flight from theory. But Greiner and Matthews (2016), in their comprehensive review of randomized controlled trials in law, find no tests of devices like fee shifting, damages multipliers, or changing burdens of proof in civil trials. Even if a legislature were to approve randomizing litigants into these regimes, such experiments would not be able to measure effects on primary behavior, unless litigants were randomized before cases even accrued. Natural experiments in theory could reveal effects on primary behavior variables such as accident rates. But natural experiments with strong identifications are few and far between; Helmers et al. (2021) reports a valuable experiment on fee-shifting but compares only two venues. Experimental evidence leaves questions about external validity. And so we can have little confidence that we have arrived at the optimal approaches to these most foundational aspects of our litigation system. It should not be surprising that procedural design choices vary across countries (the American vs. the British rules are so named for a reason) and legal contexts (with antitrust and the False Claims Act in the United States being exceptional in imposing fixed treble damages and with heightened burdens of proof applying in many contexts).

The prospect that any paper with any methodology will get us to the correct answer thus seems small. But we may be able to make some progress by using new tools, particularly taking advantage of the increasing power of computation. This paper seeks to use algorithmic game theory to develop a single theoretical model that can be applied to questions of fee shifting, damages multipliers, and burdens of proof, while offering more realism than one-sided information models. The expectation is not that we will produce definitive answers about optimal design. But by varying procedural rules and other assumptions with an approach that allows more knobs and variations than most models, perhaps we might at least be able to develop a sense of the answer to the following important meta-question: How much does the choice of procedural mechanism really matter? 

Answering this question, however, requires more than a model of the litigation process itself, even with a better characterization of that process than before. To address implications of design for overall welfare, we cannot look at litigation outcome variables--such as settlement rates or accuracy--in isolation. Rather, we must assess the ramifications of changes in the litigation system for primary behavior. As Shavell (1997) recognized, litigation is rife with externalities. The mere expectation of litigation may affect third parties through deterrence (and perhaps overdeterrence), and litigants impose externalities on one another in litigation. There can thus be too much litigation or too little, but procedural mechanisms can affect the calibration of such incentives. To fully tally the consequence of different choices of procedural mechanisms, we must examine not only the effects of such mechanisms on any given suit, but also on the legal system as a whole. Even if we cannot be sure of the precise consequences of procedural choices for litigation costs, we may be able to gain appreciation of the extent to which the system can equilibrate. For example, to what extent might increases in the cost of trying any particular case be made up by a reduction in the number of cases overall, either because fewer disputes arise (perhaps because of less injury) or because more cases settle?

Given the challenges of mathematical modeling, the theoretical literature has for the most part avoided the challenge of simultaneously modeling both the generation of disputes and the litigation process that resolves them. Models of the tort process often take the litigation system as a given, for example by assuming a fixed cost of litigation cost without fully assessing the dynamics of trial. Shavell (1980)'s canonical comparison of strict liability versus negligence assumes the absence of litigation costs, and even many more modern models, such as Baumann and Rasch (2024)'s model of product liability, reasonably adopt a similar assumption. Meanwhile, models of the litigation process itself, such as models of fee shifting, may begin from the assumption that a dispute has occurred, thus ignoring the possibility that a different litigation system might have avoided an accident or other source of controversy. Argenton and Wang (2023) is just one of many recent examples that assume the existence of a dispute because doing so allows undistracted focus on the litigation process.

Some modelers have commented on the design of the litigation process using models in which the generation of disputes is endogenous, but have been forced to accept great simplifications about the process of adjudication itself. Png (1987)'s model is one of the first in which injurers vary in the cost of care and choose care endogenously, and the entire game is simplified into a extensive form game tree with only 15 nodes. His model demonstrates that the litigation process shapes incentives for care but leaves open many interesting questions of institutional design. Polinsky and Rubinfeld (1988) show that optimal liability may require an increase or decrease in damages to balance the goals of optimizing care and minimizing litigation expenditures, but they unrealistically assume no judicial error. Spier (1994) provides a sophisticated model of settlement bargaining and explores trade-offs with respect to whether damages awards should be finely tuned to the level of harm, but she too assumes no errors in measuring liability. Meanwhile, Polinsky and Shavell (2014) allow for litigants to face fixed and variable costs of litigation depending on the level of damages, but courts again adjudicate without error. Yet the possibility of judicial error may be critical to assessing the efficiency of procedural mechanisms. If, for example, treble damages are assessed sometimes against a not truly liable party, that might be problematic even if the treble damages help mitigate the danger of underdeterrence. 

One scholar has furnished a model with endogenous disputes and imperfect adjudication, Keith Hylton. Over three papers, Hylton develops what he calls a "cradle to grave" model of litigation. In his models, potential injurers must decide how much to take care, and these decisions determine how many accidents occur, which in turn result in lawsuits in which there might or might not be fee shifting. In Hylton (1990), Hylton (1993) and Hylton (2002), the potential tortfeasor draws a random cost of care and then compares it to the benefit in expected liability savings from compliance, taking into account the risk of type-1 and type-2 errors. The first article does not explicitly model settlement, while the second assumes that cases settle whenever there is a zone of agreement (that is, the plaintiff's minimum acceptable settlement is not greater than the defendant's maximum offer). The third article features a Bayesian settlement model in which plaintiffs play mixed strategies in determining whether to accept defendants' offers.  

To accomplish the remarkable feat of finding equilibria across both care and litigation decisions, Hylton necessarily must make some sacrifices in the realism of the model of litigation. While these models admit of judicial error, the risk of error is no greater when the level of care is close to the legal standard than when it is far from it. In addition, the strategic interactions between plaintiffs and defendants are stylized in order to yield tractable equilibria: bargaining is reduced to simple settlement zones in the second paper, and the informational structure is entirely one sided in the third of the trilogy, thus avoiding the methodological complexity of two-sided asymmetric information. In reality, though defendants may have more knowledge than plaintiffs of their own care decisions, that advantage is mitigated by discovery. Thus, parties are likely both informed about the probability of liability to some imperfect degree, with differences in 

Recent literature, meanwhile, has made progress in modeling two-sided asymmetric information, though without Hylton's innovation of endogenous disputes. Earlier models, such as Bebchuk (1984) and Daughety and Reinganum (1994), allowed for two-sided asymmetric information by granting each party information on different quantities, for example with one party knowing the level of damages and the other party knowing the level of liability. But Friedman and Wittman (2007) and Klerman, Lee and Liu (2018) model the situation in which each party has independent private information about the same issue, such as the level of damages. Dari-Mattiacci and Saraceno (2020) manage to incorporate an analysis of the effect of fee shifting on such information. Following Friedman and Wittman, Dari-Mattiacci and Saraceno assume that each party receives an independent signal of the level of damages and that the total damages is equal to the sum of the signals.

As Abramowicz (2025a) points out, however, tractability required a number of critical assumptions, such as relatively low litigation costs, that every potential lawsuit is always contested, and that a linkage exists between the degree of information asymmetry and the true merits of the case. Rather than complicate an already intricate mathematical model, that article switches to using a computational game theory algorithm to study similar models in which the outcome of litigation depends on the sum of the parties' signals. The linear programming algorithm, developed by von Stengel, van den Elzen, and Talman (2002), identifies exact perfect Bayesian Nash equilibria in extensive form game trees. Abramowicz (2025a) applies this algorithm to extensive form games of over 16,000 nodes, allowing incorporation and variation of a number of game features that could not easily be jointly modeled mathematically. These features include uncertainty about liability rather than damages, risk aversion, and options not to sue or defend, both at the outset of litigation and after the failure of negotiation.

The results strongly suggest that generalizations based on simpler models may not survive more robust specification. For example, while Dari-Mattiacci and Saraceno found that the English (loser pays) rule would be relatively advantageous in a jurisdiction with relatively low litigation costs and the American rule would be advantageous in a jurisdiction with relatively high litigation costs. None of the major computational specifications supported both of these results. Of course, computational results will not necessarily be robust either. Abramowicz (2025b) modifies the earlier model, featuring game trees of over 45,000 nodes that enable correlated instead of independent signals. That is, each party receives a noisy estimate of the true value of the litigation. In this setting, fee shifting can have complicated strategic effects. On one hand, it may lead parties with weak cases to give up or settle on unfavorable terms. On the other, especially when costs are relatively high, it may encourage a party to bluff in the hope that the other party will quit first. 

A significant limitation of these computational analyses is that they feature disputes that are exogenously generated, with a $\frac{1}{2}$ chance of a case being one in which the defendant is truly liable and an equal chance of being one in which the defendant is not truly liable. Truly liable cases are assumed tend to have stronger evidence for the plaintiff than not truly liable cases, but the distribution of litigation strength given true liability is also set based on an arbitrary parameter. In essence, in these models, as in many litigation models, cases in effect fall from the sky. This leaves unresolved questions of whether the conclusions would be different if there were a different distribution of truly liable vs. not truly liable cases. More critically, it elides the interaction effects between the litigation process and the generation of disputes. The computational approach to date has modeled how fee-shifting affects cost and accuracy in various environments, but it has not previously combined these considerations, as Hylton does, in an effort to identify global optimality.

This article applies algorithmic game theory, albeit with a different algorithm that makes it feasible to feature much larger game trees, each containing over 225,000 nodes. The greater size of these game trees makes it feasible to integrate potential tortfeasors' decisions about whether to take care, while still maintaining the richness of the bargaining framework of the earlier papers. It thus continues Hylton's project of modeling litigation cradle to grave, while allowing for two-sided asymmetric information. Each party's signals span multiple levels of litigation quality, and settlements can occur at each of multiple payment levels. Instead of one party being limited to accepting or rejecting the other party's settlement offer, the parties follow the Chatterjee and Samuelson (1983) bargaining protocol, in which each party submits an offer and cases settle at the midpoint if the defendant's offer equals or exceeds the plaintiff's. Although the algorithm uses floating point numbers and finds approximate equilibria, unlike the exact algorithm operating on rational numbers of the von Stengel et al. algorithm, these equilibria are measurably quite close to perfect Bayesian Nash equilibria. 

This article's analysis is not limited to fee shifting. Recognizing Craswell (1999)'s point that a variety of different types of procedural mechanisms might help achieve optimality, this article also considers two other procedural variations: damages multiples and alterations in the liability threshold. Some simulations intersect multiple such variations, to enable consideration of, for example, a regime in which it is difficult to establish liability but liability once established is heavy. With each simulation, it is possible to observe the sum of precaution, injury, and litigation costs, and differences across simulations can thus be at least tentatively attributed to differences in parameters and, in particular, differences in the procedural mechanisms used. Though it is difficult to encapsulate all of the article's findings in a single conclusion, a central point emerges: When lawsuits are generated endogenously based on the potential defendant's level of care, the adjustments in that level to the legal environment will generally prevent extreme variation in total costs. If liability levels are high, for example, precaution will be relatively high, but injury and litigation will be relatively low. That does not mean that the procedural mechanisms are entirely irrelevant, and certainly at extremes of the cost continuum (very low or very high litigation costs), some clear conclusions emerge. But the effects of even aggressive procedural mechanisms such as damages multiples are much more muted than one might think. 

[SUMMARY OF CONCLUSIONS]

\section{An Extensive Form Endogenous Litigation Game}

The approach that would be most consistent with Hylton's and indeed the broader literature on the economics of accidents would be to allow the potential defendant to choose a level of care, aware of the implications of that level for the probability that an accident occurs. Though perhaps plausible in some cases, this approach would have a serious drawback: When a case arises, the defendant would necessarily know how much care was exerted and therefore the quality of the lawsuit. The model would thus become a one-sided asymmetric information model. Yet in reality, both plaintiffs and defendants will often be uncertain about the outcome of litigation. Moreover, after initial accumulation and sharing of information, whether through formal discovery or otherwise, it is not obvious that the defendant's knowledge in every case will necessarily be better than the plaintiff's. Such an asymmetry might manifest in many cases, but it would be preferable if that possibility could be explored as one setting of the model. A neutral default setting would be one in which each side has equal insight into litigation quality. 

A modeling approach addressing this concern emerges from the recognition that in many real settings, both parties can observe what level of precaution the injurer actually took (for example, whether a machine guard was installed or which safety protocol was followed), and may even have strong information about the cost of such precautions. Meanwhile, the parties also may know what precautions the injurer forewent and how much such additional precaution might have cost. Nonetheless, there might still be uncertainty concerning how \emph{effective} the marginal precaution not taken would have been at reducing risk and whether such a risk reduction would have been cost-justified. Effectiveness depends on technological fit, local conditions, and other hidden factors that are not fully verifiable or knowable ex ante or perhaps even after an accident occurs. Such questions can be particularly challenging because they are counter-factual. Disputes in tort cases will thus often concern whether the defendant should have taken a more cautious path than the defendant actually took. To be sure, there may sometimes be debates as well as to what the defendant actually did and as to what a hypothetical precaution would have cost, but even with computation, analytic tractability makes desirable focus on a single source of uncertainty. For the purpose of the model in this article, the fount of uncertainty will thus concern the level of \emph{precaution power}, that is the extent to which expenditures on precaution would have reduced the probability of an accident. Each party knows the \emph{precaution level} but receives only a signal of precaution power. 

This section thus presents a single extensive-form model in which precaution and litigation are determined jointly in equilibrium under a negligence rule with imperfect adjudication and two-sided private information. Chance determines an underlying state that governs how effective precaution is at reducing accident risk. The defendant chooses a discrete precaution level before any accident occurs. The precaution level and chance then jointly determine whether the defendant causes an accident. If the defendant does not cause an accident, there is nonetheless some chance, unrelated to the level of precaution, that an accident is wrongly attributed to the defendant. 

Assuming an accident occurs, the plaintiff decides whether to file suit, the defendant decides whether to answer or default, the parties engage in a one-shot simultaneous-offers bargaining stage (with acceptance if the defendant’s offer weakly exceeds the plaintiff’s demand). If there is no settlement the case proceeds to trial unless one party decides to quit upon settlement failure. At trial, a court renders a binary liability verdict based on the liability threshold and on its own noisy signal of precaution power, again assuming knowledge of the precaution level. Payoffs incorporate damages (with an optional multiplier), litigation costs, and fee rules. Social welfare accounts for precaution costs, defendant-caused accident losses, and litigation costs. 

In this section, we will introduce the game by zooming into portions of a miniature version of the extensive-form game tree and then discussing the algorithm used to find perfect Bayesian Nash equilibria in these trees. More detail about the construction of the game trees is available in the appendices. Appendix A elaborates the formulas that are used for critical calculations, such as the probability of an accident and the probability that the court rules for the plaintiff in a case that goes to trial. Appendix B, meanwhile, describes a simplification that makes calculation much more feasible. The simplification is that the node in which the precaution power level is chosen can be eliminated from the game tree, so long as Bayesian probability is applied both to calculations (such as accident and trial probabilities) and to back out signal values after games are complete. This simplification was tested in relatively small trees by comparing its results to the same simulations run without simplification, and they produced identical results. The details underlying this algorithmic shortcut may be of interest primarily to readers interested in implementing similar simulations.

\subsection{Extensive-form game tree}

An extensive-form game tree can fully capture the formal game summarized above for any particular set of parameter values. The game features two strategic players and Chance. The \emph{defendant} (potential injurer) chooses whether to engage in the underlying activity, and, if so, a discrete precaution level. (The choice whether to engage in the activity and thus receive the fruits of that activity has little role in the analysis in this paper, but is included both for analytic completeness and as a source for analysis in future work.) The \emph{plaintiff} (victim) decides whether to file, whether to quit before trial if settlement fails, and which demand to submit in simultaneous offers. The defendant similarly decides whether to answer, whether to quit before trial if settlement fails, and what demand to submit. The \emph{court} is modeled as a chance node that observes a noisy liability signal at trial and returns a binary liability verdict.

In the baseline calibration used for analysis, the number of hidden precaution-power states is $n_H=8$, the number of discrete precaution levels is $n_K=8$, and each party’s liability signal has $n_{S_P}=n_{S_D}=8$ levels. In addition, the number of possible settlement offers that the plaintiff and defendant, respectively, may make, is defined as $n_{\mathcal{o}_P} = n_{\mathcal{o}_D} = 8$. In the miniaturized version of the game tree explored here, $n_H = n_K = n_{S_P} = n_{S_D} = n_{\mathcal{o}_P} = n_{\mathcal{o}_D} = 2$ (for the hidden state, precaution levels, and the plaintiff/defendant signals and offers). Otherwise, parameters are set to the baseline values that we use in the simulation with the larger tree. Figure \ref{fig:smalltree} provides a zoomed-out view of the miniaturized version of the game. This is designed solely to provide context and a sense of the game complexity even in this miniature game. We must now zoom into particular portions of the game tree to allow for clearer explication of the game.

 \begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth,height=0.3\textheight]{../Figures/smalltree.pdf}
  \caption{Zoomed out version of the miniaturized version of the game tree.}
  \label{fig:smalltree}
\end{figure}

The game proceeds in three broad stages. For each stage, we first present the technical structure of the game, and then discuss how the corresponding figure illustrates that structure. 

Figure \ref{fig:smalltree_beginning} provides the first stage in the miniature version of the game. The diagram shows the split of hidden states representing precaution power at the left, the branching for defendant and plaintiff signals just to the right, the defendant’s decision to engage in the activity and select a precaution level, and the accident node at the far right. Ellipses are used to indicate the vast portions of the miniaturized game tree that are omitted. 

The numbers attached to these nodes, along with the probability estimates from the calculated Nash equilibrium in the miniaturized game, provide some intuition. In the portion of the tree fully presented in Figure \ref{fig:smalltree_beginning}, the precaution power is set randomly to a low value (0.25), with the very bottom of the diagram representing the contingency in which the precaution power is set randomly to a high value (0.75). With the low precaution power, each party is likely to receive a low signal of precaution power rather than a high signal. Indeed, with the default parameter values, there is for each party approximately an 88\% chance of receiving the signal corresponding to the correct precaution power level. Because the parties' signals are of the true value of precaution power, they will be correlated with one another. The chance probabilities are calculated based on the assumption that a draw from a random distribution is added to the true value and thus becomes noise that obfuscates it. The degree of noise determines the quality of the party's information, and here we assume that each party has equally good information about precaution power.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_beginning.pdf}
    \caption{Stage I: hidden state, private signals, activity/precaution choice, and accident realization (illustrative tree with two levels for readability).}
    \label{fig:smalltree_beginning}
  \end{figure}

The plaintiff’s and defendant’s liability signals are private; each party knows the model primitives and distributions but not the other’s realized signal or the hidden state. Actions in the litigation block to be discussed below are observed as they occur (filing, answering, offers, and quits). A party's information set consists of any signal that the party receives, the party's own decisions earlier in the game, and public decisions of the opponent. The court’s internal signal is not observed by the parties; they observe only the binary verdict. Each party has perfect recall, meaning that its own decisions and the signals available to it remain part of its information set throughout the game. The extensive form game diagrams denote information sets by placing a number next to a letter; for example, "D26" refers to a particular information set faced by the defendant at the time the defendant must determine whether to engage in the activity. The algorithm for finding a Nash equilibrium must assign a single mixed strategy (i.e., probability of choosing each action) for each information set, even though an information set may recur many times in the game tree.

Before turning to the strategic choices of the parties, it is helpful to visualize the space of possible signals in the baseline (non-miniaturized) game. Figure \ref{fig:signals_levels} depicts the full set of signal levels that plaintiffs, defendants, and courts may receive. Each signal corresponds to a midpoint bin in the unit interval, constructed by adding noise to the hidden precaution-power state. The height of each signal target represents the probability that such a signal will be received; this reflects that middling assessments will be more common than extreme ones. As explained more formally in Appendix~A, this discretization ensures that the full range of possible noisy observations is covered. The figure thus provides intuition about the informativeness of the signals used in the simulations: While the signals are imperfect, they are reasonably strong indicators of the underlying hidden state. 

\begin{figure}[t]
  \centering
  \includegraphics[width=0.75\textwidth,height=0.5\textheight]{../Figures/signals_levels.pdf}
  \caption{Signal levels in the baseline game.}
  \label{fig:signals_levels}
\end{figure}

Following receipt of signals, the defendant must choose whether to engage in the underlying activity. By engaging in the activity, the defendant receives some benefit. This might be seen as the benefit of driving instead of staying home or pursuing a business activity instead of investing in diversified mutual funds. The value of the benefit parameter is assumed to be $1.0 \times 10^{-3}$ if undertaken. This is a relatively high value relative to some of the other parameters in this simulation, and thus unless otherwise noted, the defendant always chooses to engage in the activity. This approach, however, opens up the possibility of considering not only the possibility that there might be negative consequences from underdeterrence, but also that overdeterrence of activities that have the potential to lead to tort liability could produce costs (or alternatively benefits, if the relevant activities have negative externalities apart from the torts that may be committed, though such externalities are beyond this article's scope). If the defendant decides not to engage in the underlying activity, then the defendant cannot cause injury to the plaintiff or be thought to have been responsible for any injury to the plaintiff, and so the game ends. The modeling cost of including this branch in the model is very low because it does not exponentially increase the size of the tree.

After deciding to engage in the activity, the defendant must choose a level of precaution. The lowest level of precaution is always zero, so given the assumption in this miniaturized model of only two levels of precaution, in this example the choice is the binary one whether to take a precaution or not. In the non-miniaturized game trees providing the article's actual results, the choice can span multiple layers of precaution. The incentive for greater precaution is a reduced likelihood of an accident and thus a stronger position in any hypothetical litigation. The printed probabilities on the accident branches are consistent with increased precaution reducing risk: approximately $1.10 \times 10^{-4}$ at the zero level of precaution is a higher risk than the $8.12 \times 10^{-5}$ at the higher level of precaution. These numbers are calculated via the formulas discussed in detail in the appendices.

These probability values are intentionally quite small. The small values are consistent with an environment in which accidents are highly unlikely to occur but quite costly relative to precaution cost in the event that they do occur. For example, someone driving at a high rate of speed still will generally have only a low probability of engaging in an automobile accident. Likewise, even when a dock owner improperly secures a barge, most of the time it won't drift away from the pier. An advantage of the computational game theory algorithm discussed here is that it easily accommodates this common feature of tort precaution, simply calculating the relevant probability values during its walks through the tree. By contrast, some Monte Carlo computational models might need a relatively high accident rate so that they can generate enough cases in which accidents occur to create a meaningful quantity of data. Informal experimentation, however, suggests that the results in the paper are generally qualitatively similar if accident is made much more common and precaution cost, correspondingly higher.

One detail that the formal extensive form game tree obscures is that the model allows not only for the possibility that the defendant causes an injury to the plaintiff, but also that the defendant is wrongfully concluded to have caused the plaintiff's injury. The probability of a wrongful attribution of liability (conditional on the defendant engaging in the activity but not actually causing injury to the plaintiff) is set in the baseline at $1.0 \times 10^{-5}$. This value is set so that for the values of the parameters that we choose, such wrongful attribution remains less likely than proper attribution of liability. The rare event of wrongful attribution provides a channel through which we can analyze the welfare implications of error and the efficiency of procedural mechanisms. Our analysis will also consider the implications of changing this baseline value.

The accident probabilities listed reflect the sum of the probability that the defendant causes injury to the plaintiff and that the defendant is wrongfully believed to have caused such injury. This nuance is omitted from the game tree because it has no effect whatsoever on game play. Though a more sophisticated model might explicitly model causation, that is not modeled here. Whatever the route to an injury relevant to the model, the legal attribution of causation to the defendant is assumed. The trial itself concerns only whether the defendant exercised standard care, not the issue of causation. Thus, after applying the proper formulas to identify the total accident probability, we can ignore the causation issue in finding perfect Bayesian Nash equilibria. Then, in the final accounting, we can break down the proportion of cases in which causal attribution is wrongful if desired, as will be apparent in diagrams reporting results from simulations. Note that the model does not reflect that the plaintiff may be injured by someone other than the defendant, because that has no bearing on the defendant's liability or on game play. For welfare accounting, in any event, only injuries physically caused by the defendant ($Z=1$) are included; injuries that may occur under wrongful attribution ($Z=0$) are excluded, since the welfare measure captures only the consequences of the defendant’s own activities.

If an accident occurs, the plaintiff decides whether to file suit after observing the plaintiff's private signal. If the plaintiff does file suit, the defendant then decides whether to answer (contest) or to default. A default ends the case immediately with a damages transfer per the liability rule; answering moves the case into bargaining.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_mid.pdf}
    \caption{Stage II: filing, answer/default, and entry into bargaining (illustrative tree with two levels for readability).}
    \label{fig:smalltree_mid}
  \end{figure}

After the plaintiff files and the defendant answers, we insert—before any settlement proposals—the parties’ contingent exit choices: the plaintiff may elect to abandon if bargaining later fails, and the defendant may elect to default if bargaining later fails. This placement is deliberate. Modeling these “quit if no settlement” decisions \emph{after} every possible offer profile would require intersecting abandon/default with the settlement subgame, exponentially multiplying information sets without changing what the parties can do or the distribution of outcomes. By recording the quit choices immediately after the file/answer node (and keeping them unobserved until they matter), we preserve most of the strategic richness while dramatically simplifying the tree.

Bargaining then proceeds exactly as in the models of Abramowicz (2025a) and Abramowicz (2025b). The plaintiff states a minimum monetary demand $\mathcal{o}_P$ (labeled “P Offer” in the tree diagram) and the defendant announces the most it is willing to pay $\mathcal{o}_D$ (“D Offer”). Although the diagram prints P Offer before D Offer, this ordering is irrelevant. Because the defendant does not receive information about the plaintiff offer before announcing its own amount, the decisions are effectively simultaneous. If the offers meet or cross (the defendant's offer is at least as great as the plaintiff's), the case settles at the midpoint of the two numbers and litigation ends. The defendant then pays to the plaintiff the amount of the settlement. In addition, each party pays a cost for filing or answering, as well as a cost of bargaining, but then saves the cost of trial. In the baseline condition, the stakes are normalized to $1$ and $c_{file} = c_{answer} = c_{bargain} = c_{trial} = 0.10$.

If the offers do not meet, we implement the contingent choices recorded earlier: if the plaintiff chose to abandon, the case terminates without judgment; if the defendant chose to default, judgment is entered against the defendant with the applicable damages multiplier but without fee-shifting; if both parties would quit, Chance determines which party quits first, thus saving the other the trouble. This scenario, along with successful settlements, is illustrated in Figure \ref{fig:smalltree_end}

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_end.pdf}
    \caption{Stage III: simultaneous offers and resolution of case in which settlement fails and both parties precommitted to quit.}
    \label{fig:smalltree_end}
  \end{figure}

If neither party precommitted to quit, the case proceeds to trial. At trial the court observes an imperfect signal of case quality and returns a binary liability verdict; damages and any fee shifting are applied, and remaining stage costs are assessed. Figure \ref{fig:smalltree_end_adjudication} depicts this end phase. In this case in the miniaturized version of the game, the court always finds liability. In the non-miniaturized version to be reported later, court decisions are heterogeneous at the baseline parameter values, resulting in a probability of liability between $0$ and $1$ even for a particular pair of precaution power and relative precaution levels. 

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_end_adjudication.pdf}
    \caption{Stage III: resolution by trial of case in which settlement fails and neither party precommitted to quit.}
    \label{fig:smalltree_end_adjudication}
  \end{figure}

\subsection{Algorithm}

The results in this paper are produced with \emph{counterfactual regret minimization} (CFR), a learning procedure designed for large, imperfect-information games. In spirit, CFR lets the model “play the case against itself” repeatedly. After each full pass through the litigation tree, it asks—at every decision point a party could face—how well each available action would have done relative to what was actually chosen. Actions that would have helped are given a little more weight next time; actions that would have hurt lose weight. Iterating this process drives regret toward zero at each information set and yields a strategy profile that is, in practical terms, an equilibrium.

It helps to briefly situate CFR. Exact sequence-form solvers (such as the well-known von Stengel–van den Elzen–Talman method) compute perfect equilibria on moderate-sized trees with mathematical precision. We use those where they fit, both for validation and for small benchmark specifications. But endogenous disputes with filing, answering, simultaneous offers, quit/default options, fee rules, risk attitudes, and trial—all under two-sided private information—generate trees far larger than exact methods comfortably handle. CFR is the scalable alternative: it trades proofs of exactness for speed and reach, while providing clear diagnostics of proximity to equilibrium.

Two features make CFR especially apt for litigation models. First, it learns \emph{at information sets}. A party must commit to the same mixed action wherever it cannot tell histories apart (for example, “plaintiff with a given private signal before seeing any offer”). CFR updates precisely at that granularity, which is the unit that matters for sequential rationality. Second, the learning is \emph{counterfactual}. When the algorithm evaluates, say, how generous the defendant’s offer should have been, it holds fixed the opponent’s strategy and the chance moves that make this information set arise, and it asks how outcomes downstream would have changed had the defendant alone behaved differently. This isolates the value of each alternative in a way that respects imperfect information and the logic of Bayesian updating.

Our implementation uses \emph{full-tree CFR}, not a sampling variant. Each iteration walks the entire game tree once, records the realized payoffs, computes counterfactual improvements at every information set, and then updates the mixed strategies. Three practical choices improve stability without changing the target notion of equilibrium. We begin with tiny “tremble” probabilities so all actions remain available early on; we lightly discount very old regret so the process is not hostage to early noise; and we track both the current strategy and its running average, reporting results from the latter, which is standard in this family of methods.

Because litigation is a general-sum game, CFR does not come with the same global convergence guarantees it enjoys in zero-sum settings. We therefore certify output in three ways. First, we compute \emph{exploitability}: given one party’s strategy, we solve that party’s best response and report the gain from deviating. In the specifications we present, those gains are tiny relative to case stakes. Second, where an exact solver fits (smaller trees that omit some modules), we check that CFR reproduces the exact equilibrium’s aggregate predictions. Third, we restart from diverse random initializations; when the game admits multiple equilibria, this maps distinct, stable patterns rather than a single fixed point.

CFR’s strengths match the needs of this project. Each iteration is linear in the number of decision points, so scale comes from walking the tree, not from enumerating astronomical pure strategies. The method is modular: fee-shifting rules, damages multipliers, liability thresholds, risk preferences, wrongful-attribution channels, and quit/default options enter as plug-in payoffs or additional nodes without rewriting the algorithm. It naturally accommodates two-sided private information and simultaneous offers, and though it demands perfect recall, our game trees satisfy this requirement by construction.

Its limitations deserve equal candor. CFR produces highly accurate \emph{approximations}, not certificates; closeness is demonstrated by diagnostics rather than guaranteed a priori. Results depend on discretization choices for signals, offers, and precaution levels; we therefore report robustness to grid refinements and use exact solvers for small-tree benchmarks. Multiple equilibria are a feature, not a bug, in many litigation games; CFR will converge to one, not enumerate all. Finally, full-tree passes are computationally heavy—tractable at our scales, but still the main cost driver. The total number of processor hours used to compute the data used in this paper was 640, and so using still larger trees or more exact algorithms would have been quite costly in a practical sense.

In short, CFR lets us compute equilibrium behavior in a richly specified, cradle-to-grave litigation model. We use it to solve the full endogenous-disputes game; we use exact sequence-form solvers as spot checks on reduced versions of the same game; and we use exploitability and restart tests to verify that the solutions we report are both stable and economically meaningful. A more formal presentation—still without formulas in the main text—appears in the appendix, which spells out the learning loop, the diagnostics, and the precise stopping rules we employ.

\section{Results}

This section reports the primary results. The goal is less to catalog every specification than to highlight the main comparative-statics patterns and welfare implications under the baseline and the three interventions.

\subsection{Baseline}

The results of any given simulation can be summarized easily in a diagram that illustrates social welfare losses disaggregated among precaution costs, injury costs, and litigation costs. Figure \ref{fig:baseline_costs} provides this illustration at the baseline parameter values of the simulation (which are described above and also documented in Appendix A). The diagram is divided into two parts, for the cases in which no accident occurs (and thus no potential dispute arises) and those in which there is an actual or wrongly attributed accident (and thus a potential dispute). The left side of the diagram represents the vast majority of cases, in this case approximately 99.993\%. But for the vertical axis, representing costs, the values on the left side are several orders of magnitude lower than the values on the right side. The axis scales have been carefully selected to equalize a square unit of cost on both sides of the diagram. A horizontal unit on the left side represents a far higher proportion of cases than a horizontal unit on the right side, but a vertical unit on the left side represents a much lower level of costs than a vertical unit on the right side. The exact values are chosen to ensure that the product of a horizontal and a vertical unit are the same on both the right and left sides. 

The result is that the contributions to social welfare losses of very common but low precaution costs can be directly compared to the contributions to social welfare losses of injury costs and litigation costs, which may be accrued either in cases in which the defendant has not caused any injury the plaintiff may have suffered or those in which the defendant genuinely caused an injury to the plaintiff. That these costs are the exclusive components of social welfare is a standard assumption since at least Calabresi (1970) [ADD CITE]. One can, of course, argue for a more sophisticated social welfare function. For example, it might take into account distributional consequences. In general, distributional consequences might mean that a unit of precaution is in a sense less costly than a unit of injury, since injuries are generally concentrated rather than diffuse. Determining how to weigh distributional consequences will be context-sensitive, however, and is beyond this article's scope. Another challenge to this simplistic social welfare accounting might arise from the study of procedural justice, as in Tyler (2003) [ADD CITE]. Perhaps litigation costs, particularly trial costs, promote feelings of procedural justice and increase legal compliance. Again, however, this is context-sensitive and beyond the scope here.

In Figure \ref{fig:baseline_costs}, different levels of precaution cost are visible on the left side of the diagram. This reflects that precaution power may vary and different defendants will have received different signals of precaution power and will have made different decisions based on those signals. Those precaution costs are still in principle illustrated on the right side of the diagram; that is, cases in which an injury occurred are not solely cases in which the potential defendant chose not to exercise precaution (though some might be). The precaution costs are just so much smaller than the injury costs in a case in which injury occurs that they are negligible and are not even visible on this automatically constructed diagram. Indeed, even when measured as total contributions to social welfare loss, precaution costs are, in both this diagram and those associated with the vast majority of other simulations, generally much lower than the total costs of injury. 

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Baseline (Single Row).pdf}
  \caption{Social costs with baseline parameter values.}
  \label{fig:baseline_costs}
\end{figure}

Defendants face two channels of incentive to raise precaution. First, more care lowers accident risk. In our calibration the marginal reduction in risk is front‑loaded—early units of care do most of the work—and a positive residual risk remains even at high care because accidents cannot be eliminated and a small wrongful‑attribution hazard persists. Second, more care lowers the chance of an adverse verdict and, through that, improves the defendant’s bargaining position. That leverage is weak, however, because both parties and the court observe noisy signals, so the mapping from care to liability is shallow and uncertain. Taken together, diminishing returns in accident prevention and noisy adjudication mean the marginal private benefit of very high care is often below its marginal cost, so equilibrium care typically stops short of the maximum.

Figure \ref{fig:baseline_costs},  the injuries are mostly injuries for which the defendant is truly not liable (designated as "TNL Harm" in the legend). That is, the defendant did cause such injuries, but if the court knew the precaution power and applied the Hand formula, it would find the defendant not truly liable. There are a few cases in which the defendant is truly liable. In the vast majority of cases in which harm occurs, whether the defendant is truly liable or not, no litigation occurs as a result. But there are some cases in which the plaintiff does file a claim, and in this simulation, the defendant generally answers and bargaining results. In a relatively small number of cases, a trial occurs. There is also a small sliver of cases in which causation is wrongfully attributed to the defendant and a lawsuit results (in some cases resulting in a trial), at the very left of the right side of the diagram. This sliver is much lower than the proportion of cases in which wrongful attribution occurs, because this diagram illustrates only harms attributable to the defendant's conduct, not harms that could have occurred even if the defendant had not engaged in the underlying activity. Thus, wrongfully attributable cases are included only when they lead to litigation, because the litigation costs (along with the much lower precaution costs) are the only social cost attributable to this wrongful attribution.

The story in Figure \ref{fig:baseline_costs} is straightforward, but the baseline should be read with caution. The model is richer than standard one‑shot filing/settlement/trial frameworks—endogenous disputes, two‑sided private information, and noisy adjudication—but it is not calibrated to data, and several simplifying choices matter. Bargaining is a single simultaneous‑offer round with midpoint settlement; stage costs and damages are normalized; care, signals, and offers live on discrete grids. As in Bayesian extensive‑form models generally, the Harsanyi transformation assumes common knowledge of the game form and of the signal/state distributions [CITE]. These features make equilibrium computation feasible at scale, but they limit external validity. Accordingly, absolute levels in Figure \ref{fig:baseline_costs} should be taken as illustrative. Our focus is comparative statics—how fee shifting, damages multipliers, or liability thresholds move total costs holding the environment fixed—where we can hope that many misspecifications cancel and the sign and relative magnitude of changes are more informative than the baseline levels.

\subsection{Three Independent Interventions}

\FloatBarrier
\paragraph{Damages multiplier.}  
Figure \ref{fig:damages_multiplier} demonstrates that social welfare is less sensitive to increases in the damages multiplier than one might anticipate. This is because transfers of money between plaintiff and defendant do not themselves enter the social cost accounting; what matters are changes in real expenditures on precaution, injury, and litigation. The first mechanism shaping the diagram is precaution. Higher multipliers give defendants a stronger incentive to take care, and this reduces the incidence of accidents and the costs of harm. But the precaution technology features diminishing returns: once a reasonably high level of care has been taken, further increments produce only small additional reductions in risk. The savings from fewer injuries are therefore offset by the higher precaution costs themselves, leaving total costs relatively flat through much of the multiplier range. The second mechanism is bargaining and exit. Higher potential awards do not simply push more cases into trial; rather, they encourage weak plaintiffs to refrain from filing and weak defendants to concede quickly, while cases that do enter litigation often resolve through settlement. These channels vent much of the additional pressure from increased stakes, preventing procedural expenditures from rising proportionately.  

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Damages Multiplier (All Rows).pdf}
  \caption{Cost breakdown under damages multiplier.}
  \label{fig:damages_multiplier}
\end{figure}

Taken together, these forces mean that increasing damages does not markedly change aggregate social costs until one moves to extreme settings—very high multipliers, or very high costs of litigation more generally—where the balance among precaution, injury, and litigation costs no longer offsets so neatly. At that point, the diagrams do show visible shifts, but the main lesson from the central range is that the damages multiplier has surprisingly muted welfare consequences in equilibrium.


\FloatBarrier
\paragraph{Fee shifting.}
Figure \ref{fig:fee_shifting} shows that fee shifting is even less potent than damages multiples at moving aggregate social costs. The core reason is prosaic: the dollars at issue are litigation expenses that are small relative to the unitized harm and to precaution outlays. With stakes normalized to one and per‑stage costs for filing, answering, bargaining, and trial set at modest levels, shifting those costs from loser to winner changes who writes the check more than how many real resources the system burns. In equilibrium, the channels through which fee shifting could matter—filing and answering margins, simultaneous‑offers bargaining, and quit/default choices—adjust, but mostly in ways that reallocate transfers without producing large movements in precaution, injury incidence, or procedural consumption. Across the policy range from American (no shifting) through English (full shifting) and even to multiples above one, the total bar in the diagram stays nearly flat in the baseline cost environment; visible movement appears mainly when overall costs are scaled up so far that small changes in the fraction of cases that resist settlement translate into disproportionately large resource outlays.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Fee Shifting Multiplier (All Rows).pdf}
  \caption{Cost breakdown under fee shifting.}
  \label{fig:fee_shifting}
\end{figure}

This pattern aligns with and helps reconcile several strands of the literature. Rowe’s early skepticism about general predictions for American versus English rules foreshadows the modest welfare stakes of fee allocation when the fee wedge is small relative to primary behavior costs (Rowe 1984). The sensitivity of theoretical results to settlement structure in Polinsky and Rubinfeld (1998) also resonates here: because our bargaining protocol already resolves many disputes short of trial, fee shifting has limited room to amplify or dampen procedural spending except in corner regimes. Two‑sided information models that study fee shifting’s selection effects—such as Friedman and Wittman (2007), Klerman, Lee, and Liu (2018), and Dari‑Mattiacci and Saraceno (2020)—show channels that our diagrams likewise contain: weak cases exit, strong cases obtain leverage, and some parties bluff. But with the baseline magnitudes used here, those channels mostly reshuffle payoffs rather than expand real inputs. Endogenous‑disputes perspectives in Hylton’s cradle‑to‑grave framework (1990, 1993, 2002) further suggest why: precaution and case selection co‑move to absorb policy changes, leaving total social costs comparatively insensitive unless costs or risk attitudes are extreme.

\FloatBarrier
\paragraph{Liability threshold.}
Figure \ref{fig:liability_threshold} shows somewhat larger movements than the other interventions, though most of the welfare action still occurs in corner regimes. In our baseline calibration, the defendant-favorable, higher threshold appears to minimize the sum of precaution, injury, and litigation costs. That pattern should be read with caution: our “continuous” convention for the negligence test, described in Appendix A, is more plaintiff-friendly than the discrete alternative, and so the relative efficiency of the higher liability threshold may partly reflect discreteness of action choices rather than a robust advantage of a stricter standard.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Liability Threshold (All Rows).pdf}
  \caption{Cost breakdown under liability threshold.}
  \label{fig:liability_threshold}
\end{figure}

The diagrams make clear why strict liability can perform relatively poorly once litigation costs are included, however and the reason turns on who pays costs first. In the negligence panels, the vast majority of injury is “truly not liable” harm for which plaintiffs rationally do not file; fault must be shown, so many potential disputes are screened out at the filing stage. Under strict liability, by contrast, all such harms become compensable regardless of the defendant’s care. Given our move order, plaintiffs bear the filing cost up front while defendants frequently default rather than answer, so \emph{plaintiff} litigation outlays dominate in the strict-liability rows even though defendants’ own outlays remain small. From the defendant’s perspective, litigation costs are largely external and liability is essentially inevitable, so cutting precaution can be privately sensible even when it increases harm at the margin. This asymmetric cost bearing aligns with well-known comparative statics: negligence regimes tend to generate fewer suits because fault must be established, whereas strict liability invites filing after any harmful outcome (e.g., Shavell 2003). At the same time, uncertainty about the negligence boundary gives precaution a second private payoff—reducing the probability of being held liable at all—so care is often higher under negligence than under strict liability (Calfee and Craswell 1984). Put together, the diagrams’ pattern follows: at very low costs, strict liability can be slightly more efficient because the filing burden is cheap and broader compensation modestly improves incentives; as costs rise, the plaintiff-first filing asymmetry under strict liability swamps those gains, while negligence’s screening conserves resources even if it tolerates somewhat more injury.

At the other extreme, when the liability threshold is set very high, the diagrams show precaution levels falling again. With a stringent negligence standard, the chance of being held liable is so low that the private return to additional care shrinks, and defendants rationally scale back. Litigation expenditures remain small because few plaintiffs file under that standard, but the reduction in care raises realized harm; the total social loss moves, but only modestly, reflecting the same plaintiff-first asymmetry working in the opposite direction—fewer filings and lower procedural costs, purchased by tolerating more injury.

\subsection{Combining Interventions}

\paragraph{Damages multiplier and fee shifting.}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Fee Shifting Multiplier and Damages Multiplier (All Rows).pdf}
  \caption{Cost breakdown under damages multiplier and fee shifting.}
  \label{fig:dm_fee}
\end{figure}

Figure \ref{fig:dm_fee} shows that these two levers mostly operate on different, weakly connected margins, so their joint effect is close to additive and small. The damages multiplier works, if at all, by altering precaution incentives and case selection; fee shifting reassigns relatively modest stage costs and nudges bargaining posture. Because transfers do not impact welfare and the per-stage costs are small relative to normalized harm, increasing the fee-shifting multiple barely changes real resource use, and the slope with respect to the damages multiplier looks nearly the same whether the multiple is zero, one, or even above one. Only in high-cost environments do we start to see an interaction: stronger fee shifting can accelerate exits (defaults or early settlements) in the few cases that would otherwise press on, blunting the modest procedural uptick that very large damages could induce. For most policy-relevant settings, however, the grids are flat in both directions.

\paragraph{Damages multiplier and liability threshold.}
Figure \ref{fig:dm_liability} shows that the liability threshold drives larger differences in overall social costs than the damages multiplier, and the two levers interact mostly by dampening one another rather than compounding. Within any fixed liability threshold, moving from a low to a high damages multiplier mainly shifts composition: higher precaution, fewer realized harms, modestly different bargaining and exit patterns. The total bar, however, remains nearly constant. By contrast, tightening the liability threshold from plaintiff-friendly to defendant-friendly screens out many potential claims, cutting filing and procedural expenditures regardless of the damages setting. Once that screen is in place, raising damages does little, because liability attaches so rarely. The one quadrant where some joint movement appears is when both the threshold is lenient and damages are high: here greater stakes induce quicker concessions and more precaution, tilting the mix away from injury toward care, but even then the total height remains close to neighboring panels:contentReference[oaicite:0]{index=0}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Damages Multiplier and Liability Threshold (All Rows).pdf}
  \caption{Cost breakdown under damages multiplier and liability threshold.}
  \label{fig:dm_liability}
\end{figure}

\paragraph{Fee shifting and liability threshold.}
Figure \ref{fig:fee_liability} tells a similar story: the liability threshold dominates, while fee shifting modestly reallocates costs without changing totals much. Under a plaintiff-friendly standard, stronger fee shifting increases the incentive to exit early—especially defaults—because a trial loss would carry not only one’s own costs but also the opponent’s. Default does not trigger reimbursement, so some litigation mass shifts from bargaining and trial into earlier resolution. Under a defendant-friendly standard, fee shifting scarcely matters, since few plaintiffs file and there are few losers to pay. Across all four panels, then, adjusting the liability threshold screens disputes and moves the overall bar, whereas fee shifting primarily tweaks the path to resolution and redistributes expenses between parties:contentReference[oaicite:1]{index=1}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Fee Shifting Multiplier and Liability Threshold (All Rows).pdf}
  \caption{Cost breakdown under fee shifting and liability threshold.}
  \label{fig:fee_liability}
\end{figure}

\section{Robustness Checks}

\FloatBarrier
\subsection{Imperfect Estimation}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Misestimation Level (All Rows).pdf}
  \caption{Cost breakdown under imperfect estimation.}
  \label{fig:imperfect_estimation}
\end{figure}

\FloatBarrier
\subsection{Risk Aversion}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Damages Multiplier (Risk Averse) (All Rows).pdf}
  \caption{Cost breakdown under risk aversion.}
  \label{fig:risk_aversion}
\end{figure}

\FloatBarrier
\subsection{Cost of Precaution}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Unit Precaution Cost (All Rows).pdf}
  \caption{Cost breakdown under changes in cost of precaution.}
  \label{fig:cost_precaution}
\end{figure}

\FloatBarrier
\subsection{Information Asymmetry}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Information Asymmetry (All Rows).pdf}
  \caption{Cost breakdown under information asymmetry.}
  \label{fig:info_asymmetry}
\end{figure}

\FloatBarrier
\subsection{Costs Asymmetry}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Relative Costs (All Rows).pdf}
  \caption{Cost breakdown under costs asymmetry.}
  \label{fig:costs_asymmetry}
\end{figure}

\FloatBarrier
\subsection{Wrongful Attribution Probability}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Wrongful Attribution Probability (All Rows).pdf}
  \caption{Cost breakdown under wrongful attribution probability.}
  \label{fig:wrongful_attr}
\end{figure}

\FloatBarrier
\subsection{Court Quality}
\begin{figure}[ht]
  \centering
  \includegraphics[width=0.85\textwidth]{../Figures/Cost Breakdown Court Quality (All Rows).pdf}
  \caption{Cost breakdown under court quality.}
  \label{fig:court_quality}
\end{figure}

\section{Conclusion}

\section*{Appendix A: Formal Model}

This appendix collects the mathematical details underlying the accident-probability and adjudication-resolution functions used in the model. The main text emphasizes intuition and strategic structure, while here we provide the explicit functional forms and parameterizations.

\paragraph{Hidden state and private signals.}
Nature draws a hidden precaution–power state $\theta\in\Theta=\{1,\dots,n_H\}$ uniformly. Each precaution–power level determines the \emph{center} of a precaution-power distribution for the case, not a deterministic level. We index $\theta$ onto $(0,1)$ by
\[
\varphi(\theta)\;=\;\frac{\theta}{\,n_H+1\,}.
\]
We linearly interpolate between benchmark endpoint values indexed by $\varphi=0$ and $\varphi=1$, even though realized $\varphi(\theta)$ always lies strictly in $(0,1)$.

Conditional on $\theta$, the defendant and plaintiff privately observe precaution–power signals
\[
s_D\in\mathcal{S}_D=\{1,\dots,n_{S_D}\},\qquad
s_P\in\mathcal{S}_P=\{1,\dots,n_{S_P}\}.
\]

These are calculated as follows. Let $\Phi$ denote the standard normal cdf. Each party’s signal is constructed by truncated–normal binning, using party–specific noise and grids. For the plaintiff, define $SP_j=\dfrac{j-\tfrac12}{n_{S_P}}$ for $j=1,\dots,n_{S_P}$ and
\[
\Pr(s_P=j\mid \theta)
=
\frac{
\Phi\!\left(\dfrac{SP_j+\tfrac{1}{2n_{S_P}}-\varphi(\theta)}{\sigma_L^{P}}\right)
-
\Phi\!\left(\dfrac{SP_j-\tfrac{1}{2n_{S_P}}-\varphi(\theta)}{\sigma_L^{P}}\right)
}{
\Phi\!\left(\dfrac{1-\varphi(\theta)}{\sigma_L^{P}}\right)
-
\Phi\!\left(\dfrac{-\varphi(\theta)}{\sigma_L^{P}}\right)
}.
\]
For the defendant, define $SD_j=\dfrac{j-\tfrac12}{n_{S_D}}$ analogously and replace $\sigma_L^{P}$ by $\sigma_L^{D}$. Signals are conditionally independent given $\theta$ (and therefore positively correlated unconditionally through the common hidden state). The unconditional distributions over $s_P$ and $s_D$ follow by averaging the above conditional probabilities over the uniform prior on $\theta\in\Theta$. 

Unless noted otherwise, the parties' signals use a common noise level:
$\sigma_P = \sigma_D = 0.2$ (on the $[0,1]$ latent scale). 

\paragraph{Accident probability.}

The defendant then decides whether to engage in the activity, which yields a baseline benefit of $\beta = 1.0 \times 10^{-3}$ if undertaken, and, if the defendant engages, chooses a relative precaution level $k \in K = \{0,\dots,n_K-1\}$. Note that the lowest level here corresponds to no precaution undertaken at all. We index the relative precaution level $k$ on $[0,1)$ via $\tau(k) \;=\; \frac{k}{n_K }$.

The probability that the defendant causes an accident depends jointly on the hidden precaution–power $\varphi$ and the chosen precaution level $\tau$:
\[
p_{\mathrm{caused}}(\theta,k)
\;=\;
p_{\min}\!\bigl(\varphi(\theta)\bigr)
\;+\;
\bigl(p_{\max}-p_{\min}\!\bigl(\varphi(\theta)\bigr)\bigr)\,
\bigl(1-\tau(k)\bigr)^{\,\eta\!\bigl(\varphi(\theta)\bigr)}.
\]

The function has three key ingredients. First, $p_{\max}$ is the accident probability at zero precaution. Second, $p_{\min}(\varphi)$ sets a floor that declines with $\varphi$: when precaution power is weak, accidents remain more likely even at maximum care; when precaution power is strong, precaution can reduce risk further. Third, the  $\eta(\varphi)$ curvature parameters determine how fast each probability curve bends downward as precaution increases.

This function is illustrated in Figure \ref{fig:precaution}, given that $n_K = 8$ and given baseline parameter values as follows. These accident-probability curves provide the common basis for both conventions of the marginal-benefit test (continuous derivative and discrete next-step), which are introduced in the following subsections.

\[
p_{\max}=10^{-4}, \qquad 
p_{\min}^{\varphi=0}=8\times 10^{-5}, \qquad 
p_{\min}^{\varphi=1}=2\times 10^{-5}.
\]

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\textwidth]{../Figures/precaution.pdf}
\caption{Accident probability as a function of precaution level $\tau$, for different hidden precaution–power states $\varphi(\theta)$. Higher precaution power yields lower $p_{\min}$ and faster decline of risk with $\tau$. The marginal-benefit tests introduced below (continuous derivative or discrete next-step) are applied to these same accident-probability curves.}
  \label{fig:precaution}
\end{figure}

We interpolate linearly in hidden precaution power:
\[
p_{\min}(\varphi(\theta)) = p_{\min}^{\varphi=0} +
\bigl(p_{\min}^{\varphi=1}-p_{\min}^{\varphi=0}\bigr)\,\varphi(\theta).
\]

The level of $\eta(\varphi)$ is not fixed but follows a linear schedule:
\[
\eta(\varphi(\theta)) \;=\; \eta^{\varphi=0} + 
\bigl(\eta^{\varphi=1}-\eta^{\varphi=0}\bigr)\,\varphi(\theta),
\qquad \eta(\varphi) > 1.
\]
For all parameterizations considered, we impose the constraints $p_{\min}(\varphi) \leq p_{\max}$ for every $\varphi$ and $\eta(\varphi) > 1$ for every $\varphi$. These conditions guarantee that accident probability decreases monotonically with precaution and that marginal returns to precaution vanish as $\tau \to 1$.

Each curve corresponds to a level of precaution power, with higher levels of precaution power below lower levels of precaution power, including at the endpoints. The variation in the $\eta$ parameter, however, ensures that higher precaution-power levels make more of a difference for high relative precaution levels. Note that for $\tau(k) = \tfrac{1}{8}$, the highest precaution-power level is bunched with respect to accident probability with precaution-power levels just below it, whereas the accident probability levels are more evenly spread at $\tau(k) = \tfrac{7}{8}$. If $\eta$ were constant, then there would be an equal degree of spreading at each relative precaution level. For baseline parameter values, we set
\[
\eta^{\varphi=0}=3.0, \qquad \eta^{\varphi=1}=1.5.
\]

For purposes of accident probability, only the hidden state $\theta$ and the defendant’s precaution choice $k$ matter. The court’s role and its liability signal are described separately in the trial subsection below.

\paragraph{Accident probability with wrongful attribution.}
In addition to accidents \emph{caused} by the defendant, the model allows for a small probability that an accident is \emph{wrongfully attributed} to the defendant even when in fact no accident has occurred at all or when any accident was not in fact caused by the defendant. Let $\rho\in[0,1]$ denote this wrongful–attribution parameter (interpreted as the conditional probability of legal attribution given that no accident was caused by the defendant). Given the per–state, per–precaution probability of a caused accident $p_{\mathrm{caused}}(\theta,k)$, we define
\[
p_{\mathrm{wrong}}(\theta,k)\;=\;\bigl(1 - p_{\mathrm{caused}}(\theta,k)\bigr)\,\rho,
\qquad
p_{\mathrm{acc}}(\theta,k)\;=\;p_{\mathrm{caused}}(\theta,k)\;+\;p_{\mathrm{wrong}}(\theta,k).
\]
Equivalently,
\[
p_{\mathrm{acc}}(\theta,k)
\;=\;\rho \;+\; \bigl(1-\rho\bigr)\,p_{\mathrm{caused}}(\theta,k),
\]
so that $p_{\mathrm{acc}}(\theta,k)$ is the total probability that an accident is (legally) attributed to the defendant at $(\theta,k)$, combining true causation and wrongful attribution.
Let $A\in\{0,1\}$ denote the legally attributed-accident indicator, with $\Pr(A=1\mid \theta,k)=p_{\mathrm{acc}}(\theta,k)$.

Although defendants choose from the discrete grid $k\in\{0,\dots,n_K-1\}$ with $\tau_k=k/n_K$, the court may apply either the continuous or the discrete marginal test, depending on the convention selected. Under the \emph{continuous} convention, there is no discrete safe harbor at the top step: the court evaluates the benefit of further precaution via $\Delta(\theta,\tau_{n_K-1})>0$ whenever $\tau_{n_K-1}<1$. This reflects the modeling philosophy that real-world care is refinable even when our action set is discretized for computation. Under the \emph{discrete} convention, by contrast, the incremental benefit at $k=n_K-1$ is defined to be $0$, so the top step always provides a safe harbor. In both cases, increasing $n_K$ makes the discrete grid approximate the continuous ideal more closely, so that results under the two conventions converge as the action space becomes finer.

\paragraph{Filing, answering, and quitting.}
Following an accident realization, the plaintiff, who has observed $s_P$, chooses whether to \emph{file}, incurring $c_{file}=0.10$ if she does so. If the plaintiff files, the defendant observes $s_D$ and chooses whether to \emph{answer} or \emph{default}. Answering imposes $c_{answer}=0.10$ and moves the case into bargaining. Default ends the case immediately with a plaintiff judgment for normalized damages $\mu$, without any bargaining or trial costs.

If the defendant answers, each party makes a one–time \emph{quit commitment} that is implemented if bargaining fails: the plaintiff may precommit to \emph{abandon} (ending the case with no judgment), and the defendant may precommit to \emph{default} (ending the case with a judgment of $\mu$ for the plaintiff). If both precommit to quit and no settlement occurs, a symmetric chance node resolves which commitment is implemented; if neither precommits, the case proceeds to trial if bargaining fails. These commitments are made once, at the entry to bargaining, and cannot be revised thereafter.

\paragraph{Bargaining (simultaneous offers).}
Bargaining consists of a single round of \emph{simultaneous} monetary offers on finite grids $\mathcal{O}_P\subset[0,1]$ and $\mathcal{O}_D\subset[0,1]$. The plaintiff demands $\mathcal{o}_P\in\mathcal{O}_P$ and the defendant offers $\mathcal{o}_D\in\mathcal{O}_D$ simultaneously. The per–party bargaining stage cost $c_{bargain}=0.10$ is incurred by any party that participates in this round.

A settlement occurs if and only if the offers meet: $\mathcal{o}_D\ge \mathcal{o}_P$. When settlement occurs, the transfer is the midpoint of the two offers,
\[
T \;=\; \frac{\mathcal{o}_P+\mathcal{o}_D}{2}\in[0,1],
\]
and the case terminates without trial. No damages multiplier or fee–shifting applies to settlements (this model contains no Rule 68 or offer–of–judgment mechanism). If the offers do not meet, the game implements the previously recorded quit commitments (abandon or default); if neither party precommitted, the case proceeds to trial.

\paragraph{Trial.}
When bargaining fails, the court draws a discrete precaution–power signal
\[
s_C \in \mathcal{S}_C=\{1,\dots,n_{S_C}\},
\]
with distribution conditioned on the hidden precaution–power state $\theta$ by the same truncated–normal mechanism used for party signals. Let $SC_j=\dfrac{j-\tfrac12}{n_{S_C}}$ and let $\sigma_L^{C}>0$ denote the court’s noise parameter. Then
\[
\Pr(s_C=j\mid \theta)
=
\frac{
\Phi\!\left(\dfrac{SC_j+\tfrac{1}{2n_{S_C}}-\varphi(\theta)}{\sigma_L^{C}}\right)
-
\Phi\!\left(\dfrac{SC_j-\tfrac{1}{2n_{S_C}}-\varphi(\theta)}{\sigma_L^{C}}\right)
}{
\Phi\!\left(\dfrac{1-\varphi(\theta)}{\sigma_L^{C}}\right)
-
\Phi\!\left(\dfrac{-\varphi(\theta)}{\sigma_L^{C}}\right)
},
\qquad j=1,\dots,n_{S_C}.
\]
Unless noted otherwise, the court's signal is equal in strength to the parties: $\sigma_C = \sigma_P = \sigma_D= 0.2$ (on the $[0,1]$ latent scale). Conditional on $\theta$, the court signal is independent of the parties’ signals; the correlation among all signals arises through the shared hidden state. In the baseline model, the court does not condition its liability determination on whether an accident has occurred. This reflects the idea that the Hand-formula style negligence test is applied ex ante, using only cost and risk information rather than case-selection data. As a result, the court’s decision depends solely on its noisy observation of $\theta$, not on the fact that the dispute reached litigation. Formally, we model
\[
\Pr(V=1 \mid \theta,k,s_C) \quad \text{rather than} \quad \Pr(V=1 \mid \theta,k,s_C,\text{accident}),
\]
so that the court’s liability probability is unaffected by the event that a case is filed. This independence from case selection applies only to the court’s negligence test itself. In Appendix B, ex-ante probabilities are updated conditional on whether an accident was realized, but this conditioning affects only Bayesian accounting of states and signals. It does not alter the court’s liability rule $\ell(c,k)$, which is applied solely to cost and risk information as if ex ante. Put differently, the court applies $\ell(c,k)$ as though ex ante; only our Bayesian updating of $\theta$ reflects case selection.

Fix a precaution level $k\in K=\{0,\dots,n_K-1\}$ and let $\tau_k=\tau(k)$. For each hidden state $\theta$, recall that the accident probability is
\[
p_{\mathrm{acc}}(\theta,\tau)
=\rho+(1-\rho)\Bigl[p_{\min}\!\bigl(\varphi(\theta)\bigr)
+\bigl(p_{\max}-p_{\min}\!\bigl(\varphi(\theta)\bigr)\bigr)\,(1-\tau)^{\eta(\varphi(\theta))}\Bigr].
\]
\paragraph{Discrete vs. continuous marginal benefit.}
The code supports \emph{two} conventions for evaluating the marginal reduction in accident risk at a precaution level \(\tau_k\): a continuous derivative and a discrete “next-step” difference. Each has advantages and drawbacks, both as a model of real precaution decisions and as a computational device. From the behavioral perspective, some contexts plausibly involve continuous precaution choices (e.g., investment in maintenance effort or the level of monitoring intensity), while in many legal–institutional settings defendants face only finitely many meaningful care levels (e.g., whether to install a guardrail or not). From the modeling perspective, the continuous approach is analytically smooth and aligns with solvers that assume fine granularity, whereas the discrete approach aligns exactly with a finite action space and permits cleaner welfare comparisons when care levels are indivisible. [SPECIFY WHICH WE ARE CHOOSING -- OTHER CAN BE A ROBUSTNESS CHECK.]

\medskip
\noindent\textbf{Continuous-derivative convention.}
With sign chosen so that benefits are nonnegative, the marginal benefit at \(\tau_k\) is
\[
\Delta(\theta,\tau_k)
\;=\;-\frac{\partial p_{\mathrm{acc}}(\theta,\tau)}{\partial \tau}\Big|_{\tau=\tau_k}
\;=\;(1-\rho)\,\Bigl(p_{\max}-p_{\min}\!\bigl(\varphi(\theta)\bigr)\Bigr)\,\eta\!\bigl(\varphi(\theta)\bigr)\,(1-\tau_k)^{\eta(\varphi(\theta))-1},
\]
so \(\Delta(\theta,\tau_k)\ge 0\) for \(\tau_k\in[0,1)\) and \(\Delta(\theta,1)=0\) (since \(\eta(\varphi)>1\)). Let \(\bar{\Delta}(c,k)\) denote the posterior expectation of \(\Delta(\theta,\tau_k)\) given the court’s signal \(s_C=c\). The court compares the expected marginal benefit to the \emph{per-unit-\(\tau\)} cost,
\[
R_{\mathrm{cont}}(c,k)\;=\;\frac{\bar{\Delta}(c,k)}{\,n_K\,c_{\mathrm{prec}}\,},
\qquad
V=\mathbf{1}\!\{R_{\mathrm{cont}}(c,k)>\lambda\},
\]
where \(n_K c_{\mathrm{prec}}\) rescales the discrete unit cost \(c_{\mathrm{prec}}\) to the cost of a unit change in \(\tau\).

\medskip
\noindent\textbf{Discrete “next-step” convention.}
Alternatively, we define marginal benefit as the risk reduction from taking the next available step of care:
\[
\Delta^{\mathrm{disc}}(\theta,\tau_k)\;=\;
\begin{cases}
p_{\mathrm{acc}}(\theta,\tau_k)\;-\;p_{\mathrm{acc}}\!\bigl(\theta,\tau_{k+1}\bigr), & k<n_K-1,\\[4pt]
0, & k=n_K-1,
\end{cases}
\]
which is nonnegative because accident risk is decreasing in precaution. Since \(p_{\mathrm{acc}}=\rho+(1-\rho)\,p_{\mathrm{caused}}\), the wrongful-attribution term \(\rho\) cancels in the difference and the discount by \((1-\rho)\) is implicit, just as in the continuous case. With \(\bar{\Delta}^{\mathrm{disc}}(c,k)\) the posterior expectation of \(\Delta^{\mathrm{disc}}(\theta,\tau_k)\) given \(s_C=c\), the court compares the \emph{discrete} expected benefit of the next step to the \emph{cost of one step}:
\[
R_{\mathrm{disc}}(c,k)\;=\;\frac{\bar{\Delta}^{\mathrm{disc}}(c,k)}{\,c_{\mathrm{prec}}\,},
\qquad
V=\mathbf{1}\!\{R_{\mathrm{disc}}(c,k)>\lambda\}.
\]
At the top level \(k=n_K-1\) the incremental benefit is defined as \(0\) because no further step is available (a “safe harbor” boundary condition).

\medskip
\noindent\textbf{Posterior expectation of marginal benefit.}
Having specified the marginal-benefit convention—whether continuous or discrete—we can now turn to how the court evaluates the expected benefit of an additional precaution, conditional on its signal. Given a realized court signal $s_C=c$, Bayes’ rule with the uniform prior $\Pr(\theta)=1/n_H$ gives the posterior distribution $\Pr(\theta \mid s_C=c)$. The expected marginal reduction at $(c,k)$ is
\[
\bar{\Delta}(c,k)\;=\;\sum_{\theta\in\Theta}\Delta^{*}(\theta,\tau_k)\,\Pr(\theta\mid s_C=c),
\]
where $\Delta^{*}$ denotes either the continuous derivative $\Delta$ or the discrete difference $\Delta^{\mathrm{disc}}$, depending on the convention in use. The posterior $\Pr(\theta\mid s_C=c)$ is formed from the ex ante prior (i.e., it does not condition on $A$); in particular, we ignore case-selection effects when computing $\bar{\Delta}$.

Because accident harm is normalized to $1$, the expected benefit of additional precaution equals $\bar{\Delta}(c,k)$. Let $c_{\mathrm{prec}}>0$ denote the cost of one discrete step in $k$. Under the continuous convention (derivative per unit $\tau$), the court compares
\[
R_{\mathrm{cont}}(c,k)=\frac{\bar{\Delta}(c,k)}{\,n_K\,c_{\mathrm{prec}}\,},
\]
where $n_K c_{\mathrm{prec}}$ is the cost per unit $\tau$. Under the discrete convention (benefit of the next step), the court compares
\[
R_{\mathrm{disc}}(c,k)=\frac{\bar{\Delta}(c,k)}{\,c_{\mathrm{prec}}\,}.
\]
For brevity, let $R_\star(c,k)$ denote the applicable ratio given the chosen convention.


For a negligence threshold parameter $\lambda \ge 0$, the verdict is
\[
V=\mathbf{1}\!\left\{\,R_\star(c,k)>\lambda\,\right\}.
\]
The baseline analysis sets $\lambda=1$, corresponding to the familiar benefit–cost test. We also examine alternative values $\lambda\in\{0,0.8,1.2,2\}$ to capture more lenient or stricter liability standards. 

At the top step $k=n_K-1$, the treatment depends on which marginal-benefit convention is applied. Under the \emph{continuous} convention, there is no discrete safe harbor: the court evaluates the benefit of further precaution via $\Delta(\theta,\tau_{n_K-1})>0$ whenever $\tau_{n_K-1}<1$, reflecting the modeling philosophy that real-world care is refinable even when our action set is discretized for computation. Under the \emph{discrete} convention, by contrast, the incremental benefit at $k=n_K-1$ is defined as $0$, so the top step always provides a safe harbor. As $n_K$ increases, the discrete grid approximates the continuous ideal more closely, so results under the two conventions converge. Parameterizations that imply frequent liability at high $k$ are therefore interpretable as environments with unusually high residual returns to care (large $\eta(\varphi)$ or wide $p_{\max}-p_{\min}(\varphi)$) or relatively low marginal cost (small $c_{\mathrm{prec}}$), not as artifacts of the liability test.


The probability of liability at trial, conditional on the hidden state $\theta$ and the chosen precaution level $k$, is
\[
\Pr(V=1\mid \theta,k)\;=\;\sum_{c\in\mathcal{S}_C}\mathbf{1}\!\left\{R(c,k)>\lambda\right\}\,\Pr(s_C=c\mid \theta),
\qquad
\Pr(V=0\mid \theta,k)=1-\Pr(V=1\mid \theta,k).
\]
These probabilities appear explicitly in the game tree as branches following the court’s signal draw.

\paragraph{Final wealth across all case outcomes.}
Initial wealths are $W_P^{(0)}=W_D^{(0)}=10$. We also introduce a binary cause flag $Z\in\{0,1\}$, where $Z=1$ indicates that the defendant physically caused the accident and $Z=0$ indicates that any legally attributed accident was either not an accident at all or was not physically caused by the defendant (i.e., wrongful attribution). In all resolution modes, private wealth reflects only injuries physically caused by the defendant: we subtract the injury indicator $Z\in\{0,1\}$ (not the legal-attribute flag), so legally attributed but uncaused events ($A=1$, $Z=0$) do not reduce $W_P^{\mathrm{final}}$; this aligns with our welfare measure, which likewise counts only $Z=1$.
Let $C_P$ and $C_D$ denote the cumulative stage costs actually incurred along the realized path, where the baseline stage costs are
\[
c_{file}=c_{answer}=c_{bargain}=c_{trial}=0.10.
\]
If the defendant chooses not to engage in the activity, the defendant's wealth (and thus social welfare) is reduced by $\beta > 0$. This convention ensures that both the cost of precaution and the opportunity cost of forgoing the activity enter social welfare with the same sign, so that precaution expenditures and non-engagement are treated consistently as resource costs offsetting the benefits of accident reduction.

\emph{Settlement.} If the parties reach settlement, with offers $\mathcal{o}_P$ and $\mathcal{o}_D$ meeting, the transfer is
\[
T \;=\; \frac{\mathcal{o}_P+\mathcal{o}_D}{2}.
\]
Final wealths are
\[
W_P^{\mathrm{final}} \;=\; W_P^{(0)} - Z - C_P + T,
\qquad
W_D^{\mathrm{final}} \;=\; W_D^{(0)} - k\,c_{\mathrm{prec}} - C_D - T.
\]
No damages multiplier or fee–shifting applies to settlements.

\emph{Trial.} If a trial occurs, let $V\in\{0,1\}$ denote the court’s verdict for the plaintiff and $J \;=\; \mu \cdot V$ the judgment, where $\mu\ge 0$ is the damages multiplier. Each side pays $c_{trial}$ in addition to earlier costs. Fee–shifting is represented by $\phi\in[0,1]$, the fraction of the prevailing party’s \emph{total} costs reimbursed by the loser (American rule: $\phi=0$; full loser–pays: $\phi=1$). Here $C_P$ and $C_D$ denote the cumulative stage costs actually incurred along the realized path (including $c_{trial}$ when trial occurs). Final wealths under trial are

\[
W_P^{\mathrm{final}}
\;=\;
W_P^{(0)} - Z - C_P + J + \phi\bigl(V\,C_P - (1-V)\,C_D\bigr),
\]
\[
W_D^{\mathrm{final}}
\;=\;
W_D^{(0)} - k\,c_{\mathrm{prec}} - C_D - J + \phi\bigl((1-V)\,C_D - V\,C_P\bigr).
\]
In the baseline with $\mu=1$ and $\phi=0$, these reduce to $W_P^{(0)}-Z-C_P+V$ and $W_D^{(0)}-k\,c_{\mathrm{prec}}-C_D-V$.

\emph{Default and Defendant quit.} If the defendant defaults—either immediately at the answering stage or later through a quit commitment after bargaining fails—the plaintiff receives a judgment of $\mu$, reflecting the damages multiplier, and fee–shifting does not apply. Final wealths are
\[
W_P^{\mathrm{final}} \;=\; W_P^{(0)} - Z - C_P + \mu,
\qquad
W_D^{\mathrm{final}} \;=\; W_D^{(0)} - k\,c_{\mathrm{prec}} - C_D - \mu,
\]
with $C_P$ and $C_D$ including only filing costs if default occurs at answering, or also bargaining costs (but not trial costs) if default occurs after bargaining fails.

\emph{Abandon.} If the plaintiff abandons through a quit commitment, no judgment is entered. Neither damages multipliers nor fee–shifting apply. Final wealths are
\[
W_P^{\mathrm{final}} \;=\; W_P^{(0)} - Z - C_P,
\qquad
W_D^{\mathrm{final}} \;=\; W_D^{(0)} - k\,c_{\mathrm{prec}} - C_D,
\]
where $C_P$ and $C_D$ include all stage costs already incurred along the realized path.

\paragraph{Final utilities.}
Let $W_i^{\mathrm{final}}$ denote party $i$'s final wealth after the litigation path has concluded.

\emph{Risk–neutral case.} With risk neutrality, utilities coincide with final wealth:
\[
U_i \;=\; W_i^{\mathrm{final}}.
\]

\emph{Risk–averse cases.} With risk aversion, we adopt a constant–absolute–risk–aversion specification,
\[
U_i \;=\; -\,\exp\!\bigl(-\alpha\,W_i^{\mathrm{final}}\bigr),
\]
where $\alpha\ge 0$ is the risk–aversion coefficient. The four calibrations used are:
\[
\alpha = 0 \quad\text{(none / risk neutral)},\qquad
\alpha = 1 \quad\text{(mild)},\qquad
\alpha = 2 \quad\text{(moderate)},\qquad
\alpha = 4 \quad\text{(high)}.
\]
With baseline wealths of $10$ and stakes of size $1$, these values span from linear preferences to substantial curvature in the utility of wealth.

\emph{Welfare reporting.} Aggregate social welfare is defined as the negative of the real resource costs:
\[
Welfare \;=\; -\bigl(\,k \cdot c_{\mathrm{prec}} \;+\; \mathbf{1}_{\{Z=1\}} \;+\; (C_P+C_D)\,\bigr)
\;-\;\mathbf{1}_{\{\neg \text{engage}\}}\,\beta.
\]
Here $c_{\mathrm{prec}}$ denotes the cost of taking one discrete step in the precaution index $k$, so that $k \cdot c_{\mathrm{prec}}$ is the total precaution expenditure chosen by the defendant. The indicator $\mathbf{1}_{\{Z=1\}}$ represents the injury loss (equal to $1$ if the accident is physically caused by the defendant, $0$ otherwise). Accidents that occur in wrongful attribution cases ($Z=0$) are not counted, since welfare includes only consequences of the defendant’s own activity. The quantity $C_P+C_D$ is the total litigation cost (the sum of stage costs incurred by both parties). The additional term $-\mathbf{1}_{\{\neg \text{engage}\}}\,\beta$ reflects the opportunity cost of forgoing the activity: when the defendant does not engage, welfare is reduced by $\beta$. Monetary transfers between plaintiff and defendant cancel in this welfare measure. This welfare measure is consistent with the earlier sign convention: both precaution expenditures and the opportunity cost of non-engagement are treated as negative contributions to welfare, so that the court’s marginal-benefit test and the welfare accounting operate on the same footing in terms of opportunity costs.

\section*{Appendix B: Bayesian Marginalization of Chance Nodes}

\subsection*{B.1 Motivation and Overview}

Explicitly modeling every chance node (random event) can cause an explosion in the size of the game tree. We thus use Bayesian marginalization of chance nodes to avoid explicitly branching on a random variable at the outset of the game. Instead, we integrate out uncertainties concerning the variable represented by the node on the fly, adjusting probabilities and outcomes accordingly. This approach keeps the tree smaller while still accounting for the uncertainty. In our litigation game, the first chance event determines the precaution power state: the hidden state of which the defendant, plaintiff, and court may eventually receive signals. Instead of selecting such a state, we can convert the game into a mathematically equivalent game. The strategic players' information sets in this game are exactly the same as those in the original game, because the hidden state never becomes part of the plaintiff's or defendant's information set. 

While in the full game the distribution of the defendant's private signal is calculated conditional on the actual hidden state, in the collapsed tree the distribution of the defendant's private signal is calculated by integrating over all such possible hidden states. Later distributions then require similar treatment. Figure~\ref{fig:signals_graph} summarizes the dependence structure among the hidden state, signals, precaution choice, and accident realization. Solid arrows indicate explicit dependencies present in both the full and collapsed trees, dotted arrows show dependencies present only in the full tree and eliminated by marginalization, and dashed arrows indicate conditional structure that arises only in the collapsed implementation.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\textwidth]{../Figures/signals_graph.pdf}
  \caption{Conditional–independence structure for signals and accident attribution.}
  \label{fig:signals_graph}
\end{figure}

With this approach, any equilibrium of the original extensive form game tree is equivalently an equilibrium of the collapsed game, and vice versa, because certain conditions hold. In particular, the equivalence requires that the eliminated chance variable never enters any player’s information set, that players have perfect recall, that no strategic decision is made in between the eliminated chance node and the downstream chance events whose distributions depend on it, and that the collapsed tree preserves the same information sets and feasible actions. Under these conditions, the collapsed and full trees induce the same distribution over terminal histories and therefore share the same equilibria.

Figure \ref{fig:smalltree_collapsed_beginning} illustrates the beginning of the extensive form game in which the node selecting precaution power is omitted. The first node now represents the defendant's signal. Because this is not conditioned on the hidden state, in this particular miniaturized calibration the defendant has equal probability of receiving a low or a high signal. In the general model, the distribution across signals depends on the noise parameters chosen. Instead of immediately calculating the plaintiff's signal, the defendant makes its decisions on whether to engage in the activity and if so, what relative level of precaution to take. The next node then represents the accident, and the accident probabilities are calculated by integrating over both possible hidden states in this miniaturized game. Finally, the plaintiff's signal node now follows the accident node. The probability that the plaintiff will receive each of the two possible signals takes into account the defendant's signal, the defendant's precaution level, and the occurrence of the accident, integrating again over both possible hidden states. Note that in this case, the plaintiff is much more likely to receive the low signal, because that is the signal that the defendant received. It would equivalently be possible to position the plaintiff's signal node immediately after the defendant signal and then condition the accident probability on the parties' joint signals, but this approach produces a smaller game tree.

  \begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{../Figures/smalltree_collapsed_beginning.pdf}
    \caption{Beginning of the collapsed game.}
    \label{fig:smalltree_collapsed_beginning}
  \end{figure}

This section explains more formally how those probability adjustments are computed using Bayes’ rule, and how we handle missing (latent) variables by splitting game records with appropriate weights after the play-through. The goal is to produce the same expected outcomes as the full model, but with far fewer nodes in the game tree.

\subsection*{B.2 Bayesian Updates for Chance Probabilities in the Simplified Tree}

When chance nodes are marginalized, we must update the probabilities of subsequent events based on whatever partial information is revealed. We apply Bayes’ rule to revise distributions as new evidence (signals or outcomes) arrives. For each eliminated chance node, we provide the corresponding marginalization formula. The order of presentation follows the order in which these chance nodes would be encountered in play with marginalization: the defendant’s signal, the accident outcome, the plaintiff’s signal, and finally the court’s liability decision.

\paragraph{Defendant’s liability signal and posterior over the hidden state.} 
Let $\Theta=\{1,\dots,n_H\}$ index the hidden precaution–power state and let $s_D\in\mathcal{S}_D=\{1,\dots,n_{S_D}\}$ denote the defendant’s liability signal, with prior $\Pr(\theta)=1/n_H$ and conditional likelihoods $\Pr(s_D=j\mid \theta)$ as in Appendix~A. In the collapsed-tree implementation, we do not draw $\theta$ explicitly before the defendant’s signal is realized. Instead, the chance node for $s_D$ uses the unconditional (marginal) distribution \[ \Pr(s_D=j) \;=\; \sum_{\theta\in\Theta}\Pr(s_D=j\mid \theta)\Pr(\theta) \;=\; \frac{1}{n_H}\sum_{\theta=1}^{n_H}\Pr(s_D=j\mid \theta), \qquad j=1,\dots,n_{S_D}. \] Upon observing a particular realization $d\in\mathcal{S}_D$, beliefs over $\theta$ are updated by Bayes’ rule: \[ \Pr(\theta\mid s_D=d) \;=\; \frac{\Pr(s_D=d\mid \theta)\Pr(\theta)}{\sum_{\theta'\in\Theta}\Pr(s_D=d\mid \theta')\Pr(\theta')} \;=\; \frac{\Pr(s_D=d\mid \theta)}{\sum_{\theta'=1}^{n_H}\Pr(s_D=d\mid \theta')}, \qquad \theta=1,\dots,n_H, \] where the second equality uses the uniform prior $\Pr(\theta)=1/n_H$. The vector $\bigl(\Pr(\theta\mid s_D=d)\bigr)_{\theta\in\Theta}$ serves as the posterior over hidden states that conditions all downstream collapsed-node probabilities (e.g., accident occurrence and court outcomes), while the marginal $\bigl(\Pr(s_D=j)\bigr)_{j\in\mathcal{S}_D}$ determines the branching probabilities at the defendant-signal chance node.

\paragraph{Accident occurrence (Bayesian marginalization).}
Let $A\in\{0,1\}$ indicate whether an accident is legally attributed to the defendant ($A=1$) or not ($A=0$), conditional on engagement in the activity and a fixed precaution level $k\in K$. Appendix~A defined the overall accident probability
\[
p_{\mathrm{acc}}(\theta,k) \;=\; \Pr(A=1 \mid \theta,k),
\]
which aggregates both true causation and wrongful attribution. In the collapsed tree, the hidden state $\theta\in\Theta=\{1,\dots,n_H\}$ is not drawn before the accident node. Instead, after observing the defendant’s signal $s_D=d$, we branch at the accident node using the mixture of state–contingent accident probabilities,
\[
\begin{aligned}
\Pr(A=1 \mid s_D=d,\,k) 
   &= \sum_{\theta\in\Theta} p_{\mathrm{acc}}(\theta,k)\,\Pr(\theta \mid s_D=d), \\
\Pr(A=0 \mid s_D=d,\,k) 
   &= 1-\Pr(A=1 \mid s_D=d,\,k).
\end{aligned}
\]
If no informative signal has been observed, the uniform prior $\Pr(\theta)=1/n_H$ is used in place of $\Pr(\theta \mid s_D=d)$.

\medskip
\noindent\textbf{Belief updating after the accident realization.}
When the outcome $A$ is realized, beliefs over $\theta$ are refined by Bayes’ rule. For $A=1$,
\[
\Pr(\theta \mid s_D=d,\,A=1,\,k)
\;=\;
\frac{p_{\mathrm{acc}}(\theta,k)\,\Pr(\theta \mid s_D=d)}
{\sum_{\theta'\in\Theta} p_{\mathrm{acc}}(\theta',k)\,\Pr(\theta' \mid s_D=d)}\,,
\qquad \theta\in\Theta,
\]
and for $A=0$,
\[
\Pr(\theta \mid s_D=d,\,A=0,\,k)
\;=\;
\frac{\bigl(1-p_{\mathrm{acc}}(\theta,k)\bigr)\,\Pr(\theta \mid s_D=d)}
{\sum_{\theta'\in\Theta} \bigl(1-p_{\mathrm{acc}}(\theta',k)\bigr)\,\Pr(\theta' \mid s_D=d)}\,,
\qquad \theta\in\Theta.
\]
These posteriors become the belief states conditioning all downstream collapsed chance nodes, in particular the plaintiff’s signal.

\paragraph{Plaintiff’s liability signal.}
The plaintiff’s liability signal is drawn only after both the defendant’s signal and the accident outcome have been realized. Its distribution thus depends on three factors: the defendant’s observed signal $s_D=d$, the relative precaution level $k$ (which is publicly observed once chosen), and the accident outcome $A\in\{0,1\}$. Each of these observations filters the set of possible hidden states. The defendant’s signal provides an initial posterior, the occurrence or non-occurrence of an accident at precaution level $k$ further refines that posterior, and the precaution level itself matters because it shapes the accident probabilities $p_{\mathrm{acc}}(\theta,k)$ that enter those Bayesian updates.

Formally, the branching probabilities for the plaintiff’s signal are
\[
\Pr(s_P=j \mid s_D=d,\,A,\,k)
\;=\;\sum_{\theta\in\Theta} \Pr(s_P=j \mid \theta)\,\Pr(\theta \mid s_D=d,\,A,\,k),
\qquad j=1,\dots,n_{S_P}.
\]
Here $\Pr(\theta \mid s_D=d,\,A,\,k)$ is the posterior over hidden states derived in the accident step. Thus, the plaintiff’s evidence is generated from a mixture of state–conditional signal distributions weighted by beliefs that already incorporate the defendant’s signal, the accident outcome, and the level of precaution taken. The appearance of $s_D$ in this expression reflects only how the generative probabilities are computed; the plaintiff does not observe the defendant’s private signal, and therefore strategies at plaintiff information sets cannot condition on $s_D$ directly.

Observing a specific plaintiff signal $s_P=p$ then produces an additional Bayesian update:
\[
\Pr(\theta \mid s_D=d,\,A,\,k,\,s_P=p)
\;=\;
\frac{\Pr(s_P=p \mid \theta)\,\Pr(\theta \mid s_D=d,\,A,\,k)}
{\sum_{\theta'\in\Theta} \Pr(s_P=p \mid \theta')\,\Pr(\theta' \mid s_D=d,\,A,\,k)},
\qquad \theta\in\Theta.
\]
In other words, the plaintiff’s signal functions as a further noisy measurement of the latent precaution–power state, layered on top of the information already provided by the defendant’s signal, the accident outcome, and the chosen precaution level. The resulting posterior conditions the final stage of the game, the court’s liability decision.

\paragraph{Court’s liability decision.} The final chance event in the collapsed tree is the court’s verdict at trial. Let $V\in\{0,1\}$ denote the court’s binary decision, with $V=1$ indicating a finding of liability. In the explicit game tree of Appendix~A, the verdict depends on the hidden state $\theta$, the chosen precaution level $k$, and the court’s own noisy signal $s_C\in\mathcal{S}_C$ of precaution power. Because the hidden state is marginalized in the collapsed tree, we branch at the court node using the posterior beliefs about $\theta$ formed from all previous observations.

For each hidden state $\theta$, Appendix~A defined the conditional law $\Pr(s_C=c\mid \theta)$, $c\in\mathcal{S}_C$. In the collapsed tree, once the defendant’s signal $s_D$, accident outcome $A$, precaution level $k$, and possibly the plaintiff’s signal $s_P$ have been observed, the model holds a posterior distribution $\Pr(\theta \mid s_D, A, k, s_P)$ over hidden states. The unconditional distribution of the court’s signal is therefore
\[
\Pr(s_C=c \mid s_D, A, k, s_P)
= \sum_{\theta\in\Theta} \Pr(s_C=c\mid \theta)\,\Pr(\theta \mid s_D, A, k, s_P).
\]

For each $(c,k)$ pair, the liability rule determines whether the court would declare the defendant liable. Let $\ell(c,k)\in\{0,1\}$ be the indicator that the benefit–cost ratio of additional precaution exceeds the negligence threshold $\lambda$ given court signal $c$ at precaution level $k$ (as specified in Appendix~A). The probability of a liability verdict in the collapsed tree is then
\[
\Pr(V=1 \mid s_D, A, k, s_P)
= \sum_{c\in\mathcal{S}_C} \ell(c,k)\,
   \Pr(s_C=c \mid s_D, A, k, s_P),
\qquad
\Pr(V=0 \mid \cdot)=1-\Pr(V=1 \mid \cdot).
\]

If the game reaches trial and a verdict $V$ is realized, beliefs over the hidden state are updated by Bayes’ rule. For a liability verdict,
\[
\Pr(\theta \mid s_D, A, k, s_P, V=1)
= \frac{\Bigl(\sum_{c:\,\ell(c,k)=1}\Pr(s_C=c\mid \theta)\Bigr)\,
       \Pr(\theta \mid s_D, A, k, s_P)}
       {\sum_{\theta'\in\Theta}\Bigl(\sum_{c:\,\ell(c,k)=1}\Pr(s_C=c\mid \theta')\Bigr)\,
        \Pr(\theta' \mid s_D, A, k, s_P)},
\]
and for a no-liability verdict,
\[
\Pr(\theta \mid s_D, A, k, s_P, V=0)
= \frac{\Bigl(\sum_{c:\,\ell(c,k)=0}\Pr(s_C=c\mid \theta)\Bigr)\,
       \Pr(\theta \mid s_D, A, k, s_P)}
       {\sum_{\theta'\in\Theta}\Bigl(\sum_{c:\,\ell(c,k)=0}\Pr(s_C=c\mid \theta')\Bigr)\,
        \Pr(\theta' \mid s_D, A, k, s_P)}.
\]
These posteriors provide the probability weights over hidden states that are used to assign concrete values when outcomes are tabulated.

\subsection*{B.3 Ex Post Attribution and State Reconstruction for Reporting}

We record realized play and then, when needed for reporting, clone records to fill in the hidden state $\theta$ and whether a legally attributed accident is truly caused by the defendant. The cloning weights are chosen to reproduce the expectations of the explicit tree.

\paragraph{Latent pieces.}
Let $\theta\in\Theta=\{1,\dots,n_H\}$ be the hidden precaution--power state. Introduce a cause flag $Z\in\{0,1\}$ with $Z=1$ if the accident is \emph{truly caused by the defendant} and $Z=0$ otherwise. Let $s_D=d$ and $s_P=p$ be the realized defendant and plaintiff liability signals, and let $k$ be the realized precaution level. Denote by
\[
\pi_\theta \;=\; \Pr\!\bigl(\theta \mid s_D=d,\,\text{accident flag},\,k,\,s_P=p,\,\text{and, if the case proceeds to trial, the verdict }V\bigr)
\]
the posterior over hidden states implied by the collapsed updates (B.2). Define the \emph{state-specific} wrongful-attribution ratio
\[
r_\theta(k)\;=\;
\begin{cases}
\dfrac{p_{\mathrm{wrong}}(\theta,k)}{p_{\mathrm{acc}}(\theta,k)}, & \text{if } p_{\mathrm{acc}}(\theta,k) > 0,\\[1.2ex]
0, & \text{if } p_{\mathrm{acc}}(\theta,k) = 0,
\end{cases}
\]
where $p_{\mathrm{wrong}}(\theta,k)$ and $p_{\mathrm{acc}}(\theta,k)$ are given in Appendix~A (Accident probability with wrongful attribution). For an aggregate wrongful-attribution share conditional on signals and precaution, we report
\[
q_{\mathrm{wrong}}(d,p,k)\;=\;\sum_{\theta\in\Theta}\pi_\theta\,r_\theta(k).
\]
The cloning weights below use $r_\theta(k)$, not the scalar $q_{\mathrm{wrong}}(d,p,k)$.

\paragraph{Split rule.}
Create one clone for each $(\theta,z)\in\Theta\times\{0,1\}$ with weights $w(\theta,z)$:

\emph{No accident occurs.} There is nothing to split:
\[
w(\theta,1)=0,\qquad w(\theta,0)=\pi_\theta,\qquad \theta\in\Theta.
\]

\emph{An accident occurs.} Split by the \emph{state-specific} wrongful-attribution ratio $r_\theta(k)$:
\begin{align*}
w(\theta,1) &= \pi_\theta\,\bigl(1 - r_\theta(k)\bigr),\\
w(\theta,0) &= \pi_\theta\, r_\theta(k), \qquad \theta\in\Theta.
\end{align*}
Equivalently, the aggregate wrongful share equals the posterior average $\sum_{\theta\in\Theta}\pi_\theta\,r_\theta(k)=q_{\mathrm{wrong}}(d,p,k)$.

\paragraph{Averaging outcomes.}
For any statistic $X$ that depends on $(\theta,Z)$ through the primitives,
\[
\mathbb{E}\!\left[X \mid s_D=d,\,\text{accident flag},\,k,\,s_P=p,\,\text{verdict}\right]
=\sum_{\theta\in\Theta}\sum_{z\in\{0,1\}} w(\theta,z)\,X(\theta,z).
\]

\paragraph{Plaintiff signal not yet observed and no accident.}
If $s_P$ was not realized (no accident branch) and reporting requires splitting by $\theta$, sum first over possible $p$ using the mixture $P(s_P=p\mid s_D=d,\text{no-accident},k)$ and then apply the weights above (which, without an accident, reduce to $w(\theta,0)=\pi_\theta$).



\subsection*{B.4 Validation by Game-Tree Equivalence}

We verified the correctness of Bayesian marginalization by direct computational comparison. Two game trees are constructed: the original, with explicit chance nodes for hidden states and signals, and the collapsed version, with Bayesian marginalization. Both trees contain the same information sets $\mathcal{I}$, so that a random number generator $r:\mathcal{I}\to(0,1)$ can be used to generate random mixed strategies by assigning to each information set a probability distribution with all entries positive. Specifically, for each $I\in \mathcal{I}$ and each available action $a\in A(I)$, we set
\[
\sigma(a\mid I) \;\propto\; r(I,a),
\]
and normalize to obtain a probability distribution $\sigma(\cdot\mid I)$. This ensures that each information set is assigned a nondegenerate randomized strategy.

Given the same realization of $r$, we then compute players’ expected utilities in both the original and collapsed games. Because the marginalization preserves the underlying probability law, the two implementations induce the same distribution over terminal histories for any fixed behavior strategy. We verified this numerically by drawing random nondegenerate strategies and computing expected utilities in both the original and collapsed trees, finding agreement up to floating-point precision (discrepancies bounded by $10^{-12}$ in our implementation). Such rounding differences can be magnified over many iterations of regret-based algorithms, but they do not affect whether a computed outcome qualifies as an approximate Bayesian equilibrium.

\subsection{Counterfactual Regret Minimization}\label{app:CFR}

Counterfactual Regret Minimization (CFR) is an iterative algorithm (developed by Zinkevich et al.\ 2008 \cite{zinkevichetal}) for computing approximate equilibria of extensive-form games by minimizing regret at each decision point. In essence, CFR treats each player’s decision information set as an independent sub-game for the purpose of learning, and repeatedly adjusts the players’ strategy probabilities in a way that guarantees no long-run regret for any single decision. We outline here the formalism and algorithmic steps of CFR. Note that because the formalism here is independent of the specific game detailed in Appendices A and B, some of the variable names (which will generally be the same as those in the algorithmic game theory literature) may be identical to other variable names in those appendices, but no overlap is intended.

Game structure and notation. Consider a finite extensive-form game with two players (the plaintiff $\Pi$ and defendant $\Delta$, in our litigation model) and Chance. Let $H$ denote the set of all possible histories (action sequences) starting from the game’s root, and let $Z \subseteq H$ be the set of terminal histories (complete plays of the game). An information set $I$ for a player $\phi \in \{\Pi,\Delta\}$ is a set of decision nodes (histories in $H$ with $\phi$ to move) that $\phi$ cannot distinguish given their observations; at any such $I$, the same actions are available. Denote by $A(I)$ the set of actions available at information set $I$. We assume perfect recall, so that no player forgets their own earlier actions or observations; in particular, a player will never encounter the same information set more than once along any history.

For any information set $I$ belonging to player $\phi$, let $Z_I \subseteq Z$ be the set of terminal histories in which $I$ is reached.  For each terminal $z \in Z_I$, let $z_I$ denote the prefix of $z$ ending at $I$ (the history up to the decision at $I$). A strategy profile $\sigma$ specifies for each player $\phi$ and each $I$ of $\phi$ a mixed strategy $\sigma_\phi(I)$, which is a probability distribution over $A(I)$.  (Chance’s moves are also governed by fixed probabilities, which we treat as part of $\sigma$.) We write $\pi^\sigma(h)$ for the probability of a history $h \in H$ occurring when all players play according to $\sigma$.  For a prefix $z_I$ leading to information set $I$, define $\pi^\sigma(z_I)$ as the probability that the sequence of actions in $z_I$ is played under $\sigma$. We factor this into contributions from player $\phi$ and the other players (including chance): let $\pi^\sigma_{\phi}(z_I)$ be the product of the probabilities of all $\phi$’s own actions within $z_I$, and let $\pi^\sigma_{-\phi}(z_I) = \pi^\sigma(z_I) / \pi^\sigma_{\phi}(z_I)$ be the contribution of all other players and chance to the reach probability of $I$. Likewise, for any terminal $z \in Z_I$ that extends $z_I$, we denote by $\pi^\sigma(z_I, z)$ the conditional probability of reaching terminal $z$ from $I$ under strategy $\sigma$ (i.e., the product of probabilities of all actions taken *at and after* information set $I$ along the path $z_I \to z$, including $\phi$’s action at $I$ and onward). Finally, let $U_\phi(z)$ be the payoff (utility) received by player $\phi$ at terminal history $z$.

Using this notation, we define the counterfactual value at information set $I$ for player $\phi$ given a profile $\sigma$ as the expected utility to $\phi$ starting from that decision point, weighting *only the probabilities of opponents’ and chance’s moves leading to $I$ (not $\phi$’s own probability of reaching $I$)*. Formally: 

\begin{equation}\label{eq:counterfactual-value}
v_{\phi}(\sigma, I) \;=\; \sum_{z \in Z_I} \pi^\sigma_{-\phi}(z_I)\;\pi^\sigma(z_I, z)\;U_{\phi}(z)~,
\end{equation}

This $v_{\phi}(\sigma,I)$ is the expected payoff for player $\phi$ when information set $I$ is reached and all players subsequently play according to $\sigma$ (with $\phi$’s own prior reach probability factored out). Intuitively, $\pi^\sigma_{-\phi}(z_I)$ weights each possible path to $I$ by how likely the *other* players and chance make the moves leading to $I$, while $\pi^\sigma(z_I,z)$ is the probability of the continuation from $I$ to terminal $z$ under $\sigma$. Thus $v_{\phi}(\sigma,I)$ can be seen as the counterfactual expected utility for $\phi$ at $I$, conditioned on $I$ occurring but ignoring $\phi$’s contribution to reaching $I$.

Now suppose the game is played repeatedly and let $\sigma^t$ denote the strategy profile used in iteration $t$. We define the instantaneous regret for player $\phi$ at information set $I$ for not having played a particular action $a \in A(I)$ (with probability 1) in iteration $t$ as the difference in $\phi$’s counterfactual value between that unilateral action choice and the actual strategy played: 
\[
r^t(I,a) \;=\; v_{\phi}(\sigma^t_{I \to a},\, I)\;-\;v_{\phi}(\sigma^t,\, I)~,
\] 
where $\sigma^t_{I \to a}$ denotes the same profile as $\sigma^t$ except that at information set $I$, player $\phi$ plays action $a$ with certainty (probability $1$) instead of the mixed strategy $\sigma^t_\phi(I)$. In other words, $r^t(I,a)$ measures how much $\phi$ *regrets* not having played action $a$ at $I$, given the opponent’s strategy in iteration $t$. A positive regret value means action $a$ would have yielded a higher payoff to $\phi$ than the action actually used (in expectation), while a negative or zero value means $a$ would have been no better than the current choice. We then accumulate these regrets over $T$ iterations: the cumulative regret up to iteration $T$ for not playing $a$ at $I$ is 
\[ 
R^T(I,a) \;=\; \sum_{t=1}^{T} r^t(I,a)~. 
\] 
Player $\phi$’s overall goal is to minimize these regrets over time. In particular, if for every information set $I$ the average regret $\frac{1}{T}R^T(I,a)$ tends to $0$ as $T\to\infty$ for all actions $a$, then $\phi$ is said to have no regret (meaning they cannot improve their long-run average payoff by unilaterally deviating to any single fixed action at any $I$).

CFR updates the strategy profile $\sigma$ iteratively in such a way that each player’s cumulative regrets are driven toward zero. A simple but powerful update rule is regret matching (Hart and Mas-Colell 2000 \cite{hartmascolell}): in each iteration, at every information set $I$, player $\phi$ chooses actions in proportion to their positive cumulative regret so far. Formally, let $R^{t,+}(I,a) \equiv \max\{\,R^t(I,a),\,0\,\}$ denote the positive part of the cumulative regret for action $a$ (clamped at zero if regret is negative). The regret-matching strategy for the next iteration $t\!+\!1$ is then defined by: 

\begin{equation}\label{eq:regret-matching}
\sigma_{\phi}^{\,t+1}(I,a) \;=\; 
\begin{cases}
\dfrac{R^{t,+}(I,a)}{\sum_{b \in A(I)} R^{t,+}(I,b)}~, & \text{if }\sum_{b \in A(I)}R^{t,+}(I,b) > 0~, \\[2ex]
\dfrac{1}{\lvert A(I)\rvert}~, & \text{if }\sum_{b \in A(I)}R^{t,+}(I,b) = 0~,
\end{cases}
\end{equation}

Thus, $\sigma_{\phi}^{\,t+1}(I,a)$ is set to the fraction of total positive regret attributable to action $a$, and if all cumulative regrets are non-positive we default to an equal probability for each action at $I$. By construction, this update rule guarantees that actions with higher regret (those that would have provided higher payoffs in hindsight) get higher probability in the future, while actions that have never shown positive regret may be dropped to zero probability. Hart and Mas-Colell show that regret matching causes $R^T(I,a)/T \to 0$ as $T\to\infty$ for each $a$, ensuring no-regret learning at each information set.

CFR algorithm. The overall CFR algorithm alternates between strategy simulation (to gather payoff statistics and compute regrets) and strategy update (applying the regret-matching rule). Pseudocode for one player’s regret minimization is given below; in practice the procedure is run for both players simultaneously (either by alternating updates or in parallel each iteration):

\begin{algorithm}[ht]
\caption{Counterfactual Regret Minimization (for one player $\phi$)}\label{alg:CFR}
\begin{algorithmic}[1]
\State \textbf{Initialize:} For every information set $I$ of player $\phi$, set an initial strategy $\sigma_{\phi}^1(I)$ (e.g. uniform random over $A(I)$), and initialize $R^0(I,a)=0$ for all $a\in A(I)$.
\For{$t = 1,2,\dots,T$}
    \State Fix the opponent’s current strategy $\sigma_{-\phi}^t$. Traverse the game tree (e.g. via depth-first search) to compute $\;v_\phi(\sigma^t, I)$ and each $v_\phi(\sigma^t_{I\to a}, I)$ for all information sets $I$ and actions $a\in A(I)$.
    \State Compute instantaneous regrets $r^t(I,a) = v_\phi(\sigma^t_{I\to a}, I) - v_\phi(\sigma^t, I)$ for all $I,a$, and update cumulative regrets: $R^t(I,a) = R^{\,t-1}(I,a) + r^t(I,a)$.
    \State Update $\phi$’s strategy at each $I$ via regret matching: set $\sigma_{\phi}^{\,t+1}(I,\cdot)$ according to Eq.~\eqref{eq:regret-matching} using the updated $R^t(I,\cdot)$.
\EndFor
\State \textbf{Output:} The final strategy profile $\sigma^* = \sigma^{T+1}$, or (optionally) the average profile $\bar{\sigma} = \frac{1}{T}\sum_{t=1}^T \sigma^t$. 
\end{algorithmic}
\end{algorithm}

In words, at each iteration $t$ the algorithm walks the game tree under the current strategy profile to compute the payoff outcomes at all terminal nodes, then backs up those results to determine every information set’s counterfactual values $v_\phi(\sigma^t,I)$ and regrets $r^t(I,a)$. The regrets are accumulated, and then the strategy at each decision point is adjusted for the next iteration by regret matching. Because each information set $I$ is updated independently based on its own regret values, CFR effectively decomposes the global game into many local learning problems—yet it can be shown (for zero-sum games) that this process drives the overall strategy profile toward a Nash equilibrium for two-player zero-sum games, CFR converges provably to an $\epsilon$-Nash equilibrium as $T \to \infty$ \cite{zinkevichetal}.

Practical modifications. We note that many variations of the basic CFR algorithm exist to improve performance in large games. For example, one can avoid full traversals by sampling terminal paths (the Monte Carlo CFR approach, cf. Lanctot 2013 \cite{lanctot}) or use function approximation to generalize regret updates (e.g. Steinberger 2019 \cite{steinberger}). In our implementation, the game trees are of manageable size, so we employ the simplest “full-width” CFR (no sampling). However, we found it beneficial to incorporate two small enhancements to the vanilla algorithm in order to obtain better convergence in our general-sum litigation game (where theoretical convergence to Nash equilibrium is not guaranteed):

1. Outcome Perturbation (Exploration) – We require that each action has at least a small minimum probability of being played at each iteration.  Specifically, following the suggestion of Farina et al.\ (2017), we introduce a *trembling-hand* perturbation $\mathcal{P}_t>0$ such that in iteration $t$ we set 
   \[
   \sigma_{\phi}^{\,t+1}(I,a) \;\ge\; \mathcal{P}_t \qquad \text{for all $a \in A(I)$,}
   \] 
   with the probabilities renormalized if necessary.  This ensures that no action is ever completely excluded from the strategy, which is useful because an equilibrium strategy might assign zero probability to some actions that nonetheless need to be evaluated in response to an opponent’s occasional deviations. We let $\mathcal{P}_t$ decay gradually over time (starting at $\mathcal{P}_1 = 10^{-3}$ in the first iteration and reducing to $0$ by the final iteration $T$) so that the perturbation vanishes as the algorithm nears convergence.

2. Regret Discounting (Recency Weighting) – We apply a geometric discount factor to past regrets so that more recent iterations have greater influence on the strategy. In particular, after each iteration we scale down all accumulated regret values by a factor $0<\delta<1$. In our experiments we set $\delta=0.99$, meaning we multiply every $R^t(I,a)$ by $0.99$ at the end of each iteration $t$. This heuristic (inspired by Brown and Sandholm 2018 \cite{brownsandholm}) helps the algorithm respond more quickly to changing strategic dynamics and “forget” outdated early-iteration regrets. For example, if initially a defendant erroneously plays an action that yields very poor payoff, the undiscounted regrets for alternative actions might take a long time to outweigh that early mistake; discounting accelerates this re-adjustment. We found that regret discounting significantly improved stability and convergence speed in our simulations.

These modifications do not fundamentally change the CFR update rule, but they can improve the quality of the approximate equilibrium reached, especially in non-zero-sum settings. Recall that in a general-sum game, CFR (and no-regret learning in general) does not offer a theoretical guarantee of converging to a Nash equilibrium. The standard guarantee we do have is that as $T\to\infty$, each player’s average strategy will satisfy the no-regret condition, which implies the joint strategy sequence comes arbitrarily close to a coarse correlated equilibrium of the game. In particular, after $T$ iterations the players’ strategy profile $\{\sigma^t\}_{t=1}^T$ ensures that no single player could have gained more than a small amount $\epsilon$ (vanishing as $T$ grows) by unilaterally deviating to any fixed alternative strategy, on average. Formally, one can show that for any $\epsilon>0$ there exists $T_0$ such that for all $T>T_0$: 
\begin{equation}\label{eq:CCE}
\frac{1}{T}\sum_{t=1}^T U_\phi\!\big(\sigma^t_{\phi},\,\sigma^t_{-\phi}\big)\;\ge\;\frac{1}{T}\sum_{t=1}^T U_\phi\!\big(\sigma'_{\phi},\,\sigma^t_{-\phi}\big)\;-\;\epsilon~,\qquad \forall\, \sigma'_{\phi}\in\Sigma_\phi~,
\end{equation}
where $U_\phi(\sigma_\phi,\sigma_{-\phi})$ is $\phi$’s expected utility given the strategy profile $(\sigma_\phi,\sigma_{-\phi})$, and $\Sigma_\phi$ is the set of all strategies for player $\phi$. Inequality \eqref{eq:CCE} is precisely the condition that the time-averaged strategy lies in an $\epsilon$-coarse correlated equilibrium (a very weak equilibrium notion). 
\paragraph{Exploitability as a diagnostic.} 
We assess approximate equilibria by their \emph{exploitability} 
\cite{lanctot2013,johanson2011}. For each player $\phi$, let 
$U_\phi(\sigma_\phi,\sigma_{-\phi})$ be the expected payoff under profile 
$(\sigma_\phi,\sigma_{-\phi})$, and let $\sigma'_\phi$ be a best response to 
$\sigma_{-\phi}$. Exploitability for $\phi$ is
\[
E_\phi \;=\; U_\phi(\sigma'_\phi,\sigma_{-\phi}) \;-\; 
             U_\phi(\sigma_\phi,\sigma_{-\phi})~,
\]
and overall exploitability is 
\[
E \;=\; \tfrac{1}{2}\big(E_{\Pi}+E_{\Delta}\big).
\]
By definition, $E=0$ at a Nash equilibrium. 

To compute best responses, we use the forward–backward dynamic programming 
method of Johanson et al.\ (2011). This procedure calculates, in a forward pass, 
the probabilities of reaching each information set under $\sigma_{-\phi}$, then 
selects in a backward pass the action maximizing expected utility at each 
information set. 

Because the scale of payoffs varies, we normalize each player’s performance to 
the unit interval, with $0$ corresponding to the lowest attainable payoff in the 
game tree and $1$ to the highest. Exploitability values are thus reported on this 
$[0,1]$ scale. 

In our simulations, we checkpoint every 100 iterations of CFR and compute 
exploitability at each checkpoint. We then select the iteration with the lowest 
observed exploitability as the equilibrium candidate. Over the full set of 
simulations, the \emph{worst} exploitability value ever observed was only 
$4.52 \times 10^{-6}$ in normalized units, far below any economically meaningful 
threshold. This confirms that the strategy profiles identified are, for all 
practical purposes, equilibrium solutions.


\printbibliography
\end{document}
